
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>4 Testing a network against synthetic data (optional) &#8212; TM129 Robotics Practical Activities</title>
    
  <link href="../_static/css/theme.css" rel="stylesheet">
  <link href="../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.d59cb220de22ca1c485ebbdc042f0030.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="5 Feature engineering (optional)" href="07.5%20Feature%20engineering%20%28optional%29.html" />
    <link rel="prev" title="3 Training an MLP using MNIST handwritten digit data" href="07.3%20Training%20an%20MLP%20using%20MNIST%20handwritten%20digit%20data.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
      
      
      <h1 class="site-logo" id="site-title">TM129 Robotics Practical Activities</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../README_FIRST.html">
   Welcome to the TM129 Robotics block
  </a>
 </li>
</ul>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../00_FOR_VLE/Section_00_01_Introduction.html">
   1 Introduction
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../00_NOTES_FOR_TUTORS/GETTING_STARTED.html">
   Getting started
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../01.%20Introducing%20notebooks%20and%20the%20RoboLab%20environment/01.1%20Jupyter%20environment.html">
   1 Introduction to the TM129 Jupyter notebook environment
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../01.%20Introducing%20notebooks%20and%20the%20RoboLab%20environment/01.2%20Exploring%20the%20notebook%20environment.html">
     2 The interactive read-writable notebook environment
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../01.%20Introducing%20notebooks%20and%20the%20RoboLab%20environment/01.3%20Introducing%20nbev3devsim.html">
     3 The RoboLab simulated on-screen robot (
     <code class="docutils literal notranslate">
      <span class="pre">
       nbev3devsim
      </span>
     </code>
     )
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../01.%20Introducing%20notebooks%20and%20the%20RoboLab%20environment/01.4%20Exploring%20nbev3devsim.html">
     4 Exploring the
     <code class="docutils literal notranslate">
      <span class="pre">
       nbev3devsim
      </span>
     </code>
     simulator
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../01.%20Introducing%20notebooks%20and%20the%20RoboLab%20environment/01.5%20Example%20robot%20program.html">
     5 An example robot program
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../01.%20Introducing%20notebooks%20and%20the%20RoboLab%20environment/01.6%20Working%20With%20Simulators.html">
     6 Working with simulators
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../02.%20Getting%20started%20with%20robot%20and%20Python%20programming/02.1%20Robot%20programming%20constructs.html">
   1 An introduction to programming robots
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../02.%20Getting%20started%20with%20robot%20and%20Python%20programming/02.2%20Creating%20your%20own%20robot%20programs.html">
     2 Creating your own robot programs
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../02.%20Getting%20started%20with%20robot%20and%20Python%20programming/02.3%20General%20programming%20concepts.html">
     3.1 Constants and variables in programs
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../02.%20Getting%20started%20with%20robot%20and%20Python%20programming/02.4%20Getting%20started%20with%20sensors.html">
     4 Robot sensors and data logging
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../03.%20Controlling%20program%20execution%20flow/03.1%20Program%20control%20using%20for%20loops.html">
   1 Introduction to program control flow
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../03.%20Controlling%20program%20execution%20flow/03.2%20Program%20control%20using%20while%20loops%20and%20blocking.html">
     2 Program control flow using a
     <code class="docutils literal notranslate">
      <span class="pre">
       while...
      </span>
     </code>
     loop
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../03.%20Controlling%20program%20execution%20flow/03.3%20Program%20control%20flow%20using%20branches.html">
     3 Branches
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../03.%20Controlling%20program%20execution%20flow/03.4%20Example%20robot%20control%20programs.html">
     4 Example robot control programs
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../03.%20Controlling%20program%20execution%20flow/03.5%20Some%20RoboLab%20challenges.html">
     5 RoboLab challenges
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../03.%20Controlling%20program%20execution%20flow/03.6%20Optional%20RoboLab%20challenges.html">
     6 Optional challenges
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../04.%20Not%20quite%20intelligent%20robots/04.1%20Introducing%20program%20functions.html">
   1 Introduction to functions and robot control strategies
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../04.%20Not%20quite%20intelligent%20robots/04.2%20Robot%20navigation%20using%20dead%20reckoning.html">
     2 Dead reckoning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../04.%20Not%20quite%20intelligent%20robots/04.3%20Emergent%20robot%20behaviour%20and%20simple%20data%20charts.html">
     3 Emergent robot behaviour and simple data charts
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../04.%20Not%20quite%20intelligent%20robots/04.4%20Reasoning%20with%20Eliza.html">
     4 Reasoning with Eliza
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../04.%20Not%20quite%20intelligent%20robots/04.5%20Reasoning%20with%20rule%20based%20systems.html">
     5 Reasoning with rule-based systems – Durable Rules Engine
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../05.%20Experimenting%20with%20sensors/05.1%20Introducing%20sensor%20based%20control.html">
   Introduction to sensor-based control
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../06.%20Where%20in%20the%20world%20are%20we/06.1%20Introducing%20sensor%20based%20navigation.html">
   Introducing sensor-based navigation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="07.1%20Introducing%20neural%20networks.html">
   1 Introducing neural networks
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../08.%20Remote%20services%20and%20multi-agent%20systems/08.1%20Introducing%20remote%20services%20and%20multi-agent%20systems.html">
   1 An introduction to remote services and multi-agent systems
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
  <label for="toctree-checkbox-5">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../08.%20Remote%20services%20and%20multi-agent%20systems/08.2%20Collecting%20digit%20image%20and%20class%20data%20from%20the%20simulator.html">
     2 Collecting digit image and class data from the simulator
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../08.%20Remote%20services%20and%20multi-agent%20systems/08.3%20Recognising%20digits%20using%20a%20convolutional%20neural%20network%20%28optional%29.html">
     3 Recognising digits using a convolutional neural network (optional)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../08.%20Remote%20services%20and%20multi-agent%20systems/08.4%20Recognising%20patterns%20on%20the%20move.html">
     4 Recognising patterns on the move
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../08.%20Remote%20services%20and%20multi-agent%20systems/08.5%20Messaging%20in%20multi-agent%20systems.html">
     5 Messaging in multi-agent systems
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../08.%20Remote%20services%20and%20multi-agent%20systems/08.6%20Conclusion.html">
     6 Conclusion
    </a>
   </li>
  </ul>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/07. Neural networks/07.4 Testing a network against synthetic data (optional).ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
                onclick="printPdf(this)" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/executablebooks/jupyter-book/master?urlpath=tree/07. Neural networks/07.4 Testing a network against synthetic data (optional).ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show noprint">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#creating-new-images-from-old-translating-cropped-images">
   4.1 Creating new images from old – translating cropped images
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#activity-translating-the-digit-within-the-image-frame">
     4.1.1 Activity – Translating the digit within the image frame
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#example-discussion">
       Example discussion
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#testing-the-mlp-against-derived-images">
   4.2 Testing the MLP against derived images
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#activity-testing-the-mlp-against-translated-digit-images">
     4.2.1 Activity – Testing the MLP against translated digit images
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id1">
       Example discussion
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#creating-more-new-images-from-old-zooming-cropped-images">
   4.3 Creating more new images from old – zooming cropped images
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#activity-rescaling-the-digit-within-the-image-frame">
     4.3.1 Activity – Rescaling the digit within the image frame
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id2">
       Example discussion
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#activity-testing-the-network-against-lots-of-jiggled-and-zoomed-images">
     4.3.2 Activity – Testing the network against lots of jiggled and zoomed images
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#rapidly-training-the-mlp">
     4.4.1 Rapidly training the MLP
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#summary">
   4.5 Summary
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>4 Testing a network against synthetic data (optional)</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#creating-new-images-from-old-translating-cropped-images">
   4.1 Creating new images from old – translating cropped images
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#activity-translating-the-digit-within-the-image-frame">
     4.1.1 Activity – Translating the digit within the image frame
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#example-discussion">
       Example discussion
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#testing-the-mlp-against-derived-images">
   4.2 Testing the MLP against derived images
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#activity-testing-the-mlp-against-translated-digit-images">
     4.2.1 Activity – Testing the MLP against translated digit images
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id1">
       Example discussion
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#creating-more-new-images-from-old-zooming-cropped-images">
   4.3 Creating more new images from old – zooming cropped images
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#activity-rescaling-the-digit-within-the-image-frame">
     4.3.1 Activity – Rescaling the digit within the image frame
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id2">
       Example discussion
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#activity-testing-the-network-against-lots-of-jiggled-and-zoomed-images">
     4.3.2 Activity – Testing the network against lots of jiggled and zoomed images
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#rapidly-training-the-mlp">
     4.4.1 Rapidly training the MLP
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#summary">
   4.5 Summary
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            
              <div>
                
  <p><strong>This notebook contains optional study material. You are not required to work through it in order to meet the learning objectives or complete the assessments associated with this module.</strong></p>
<p><em>Brief overview: the notebook demonstrates how to generate additional training and testing image data/image label pairs by perturbing the images in the original training set.</em></p>
<div class="tex2jax_ignore mathjax_ignore section" id="testing-a-network-against-synthetic-data-optional">
<h1>4 Testing a network against synthetic data (optional)<a class="headerlink" href="#testing-a-network-against-synthetic-data-optional" title="Permalink to this headline">¶</a></h1>
<p>One of the problems associated with training neural networks is that we often need <em>a lot</em> of data in order to be able to train the network effectively.</p>
<p>One way of increasing the amount of data available to us is to generate synthetic data to supplement our collected datasets. This synthetic data may be derived from our original datasets, or created ‘from scratch’.</p>
<p>For example, with the MNIST handwritten digit image dataset, we can create derived datasets by cropping the original digits and translating them around the 28 × 28 pixel training image view. We could create completely synthetic data by taking images from computer fonts, and perhaps adding noise to them, to create new digit training images.</p>
<p><em>This notebook contains quite a lot of complex code, but you are not expected to be able to write code of this complexity, nor even to necessarily understand it. Instead, it is provided as a demonstration of what sorts of steps are required to perform particular actions, and what sort of code can be used to implement those steps.</em></p>
<p><em>So treat the notebook as if you were being given a tour of a working engineering lab: skim over the code definitions (unless you are particularly interested) and just observe the effects of calling the functions that have been implemented.</em></p>
<div class="section" id="creating-new-images-from-old-translating-cropped-images">
<h2>4.1 Creating new images from old – translating cropped images<a class="headerlink" href="#creating-new-images-from-old-translating-cropped-images" title="Permalink to this headline">¶</a></h2>
<p>To start with, let’s load in the original MNIST data as a list of images, along with the corresponding MNIST labels, using a function based on the code we used in the previous notebook:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">nn_tools.sensor_data</span> <span class="kn">import</span> <span class="n">load_MNIST_images_and_labels</span>

<span class="n">images_list</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">load_MNIST_images_and_labels</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>We can grab random samples from this data as before:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">nn_tools.sensor_data</span> <span class="kn">import</span> <span class="n">get_random_image</span>
                 
<span class="p">(</span><span class="n">test_image</span><span class="p">,</span> <span class="n">test_label</span><span class="p">)</span> <span class="o">=</span> <span class="n">get_random_image</span><span class="p">(</span><span class="n">images_list</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">show</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>You have already seen how we can get rid of the ‘background’ columns and rows around the outside of an image using the <code class="docutils literal notranslate"><span class="pre">nn_tools.sensor_data.trim_image()</span></code> function:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">nn_tools.sensor_data</span> <span class="kn">import</span> <span class="n">trim_image</span>

<span class="c1"># Pass the parameter show=False to hide the display</span>
<span class="c1"># of the untrimmed and trimmed dataframes</span>
<span class="n">trimmed_image_df</span> <span class="o">=</span> <span class="n">trim_image</span><span class="p">(</span> <span class="n">test_image</span><span class="p">,</span> <span class="n">background</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>We can also convert this dataframe back into an image:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">nn_tools.sensor_data</span> <span class="kn">import</span> <span class="n">image_from_df</span><span class="p">,</span> <span class="n">zoom_img</span>

<span class="n">cropped_image</span> <span class="o">=</span> <span class="n">image_from_df</span><span class="p">(</span><span class="n">trimmed_image_df</span><span class="p">)</span>
<span class="n">zoom_img</span><span class="p">(</span> <span class="n">cropped_image</span> <span class="p">)</span>

<span class="n">cropped_image</span><span class="o">.</span><span class="n">size</span>
</pre></div>
</div>
</div>
</div>
<p>If we create a blank image of size 28 × 28 pixels with a grey background, then we can paste a copy of our cropped image into it. The <code class="docutils literal notranslate"><span class="pre">nn_tools.sensor_data.jiggle()</span></code> function implements this approach. It will accept an image and then return a randomly translated version of it.</p>
<p>Run the following cell several times to see the effect of the <code class="docutils literal notranslate"><span class="pre">jiggle()</span></code> function on a test image.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">nn_tools.sensor_data</span> <span class="kn">import</span> <span class="n">jiggle</span>

<span class="n">jiggled_image</span> <span class="o">=</span>  <span class="n">jiggle</span><span class="p">(</span><span class="n">test_image</span><span class="p">)</span>
<span class="n">zoom_img</span><span class="p">(</span><span class="n">jiggled_image</span><span class="p">)</span>

<span class="c1"># Show size</span>
<span class="n">jiggled_image</span><span class="o">.</span><span class="n">size</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="activity-translating-the-digit-within-the-image-frame">
<h3>4.1.1 Activity – Translating the digit within the image frame<a class="headerlink" href="#activity-translating-the-digit-within-the-image-frame" title="Permalink to this headline">¶</a></h3>
<p>Explore how the <code class="docutils literal notranslate"><span class="pre">sensor_data.jiggle()</span></code> function works in practice. Run the following cell multiple times, observing what happens in each case, to see how the differently translated versions of the image are returned each time the function is called. Is there much variation in how the digit is centred in the image frame?</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">nn_tools.sensor_data</span> <span class="kn">import</span> <span class="n">jiggle</span>

<span class="c1"># Setting quiet=False displays the original input image</span>
<span class="c1"># as well as returning the jiggled image as cell output</span>
<span class="n">zoom_img</span><span class="p">(</span> <span class="n">jiggle</span><span class="p">(</span><span class="n">test_image</span><span class="p">,</span> <span class="n">quiet</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p><em>Record any notes or observations here.</em></p>
<div class="section" id="example-discussion">
<h4>Example discussion<a class="headerlink" href="#example-discussion" title="Permalink to this headline">¶</a></h4>
<p><em>Click on the arrow in the sidebar or run this cell to reveal an example discussion.</em></p>
<p>The <code class="docutils literal notranslate"><span class="pre">jiggle</span></code> function slightly translates the image to the left, right, and up and down within the image area. However, it never seems to be translated so far that bits of it get cut off.</p>
</div>
</div>
</div>
<div class="section" id="testing-the-mlp-against-derived-images">
<h2>4.2 Testing the MLP against derived images<a class="headerlink" href="#testing-the-mlp-against-derived-images" title="Permalink to this headline">¶</a></h2>
<p>Load in the MLP you saved at the end of the last notebook:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">joblib</span> <span class="kn">import</span> <span class="n">load</span>

<span class="n">MLP</span> <span class="o">=</span> <span class="n">load</span><span class="p">(</span><span class="s1">&#39;mlp_mnist_28x28.joblib&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Check that it still works with the original dataset:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">nn_tools.network_views</span> <span class="kn">import</span> <span class="n">test_and_report_random_images</span>

<span class="n">test_and_report_random_images</span><span class="p">(</span><span class="n">MLP</span><span class="p">,</span>
                              <span class="n">get_random_image</span><span class="p">,</span> <span class="n">images_list</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span>
                              <span class="n">num_samples</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="activity-testing-the-mlp-against-translated-digit-images">
<h3>4.2.1 Activity – Testing the MLP against translated digit images<a class="headerlink" href="#activity-testing-the-mlp-against-translated-digit-images" title="Permalink to this headline">¶</a></h3>
<p>Now let’s see how well our trained MLP responds to translated versions of the original training images.</p>
<p>Start by testing the network against one of the original images:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">nn_tools.network_views</span> <span class="kn">import</span> <span class="n">predict_and_report_from_image</span>

<span class="n">test_image</span><span class="p">,</span> <span class="n">test_label</span> <span class="o">=</span> <span class="n">get_random_image</span><span class="p">(</span><span class="n">images_list</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>

<span class="n">predict_and_report_from_image</span><span class="p">(</span><span class="n">MLP</span><span class="p">,</span> <span class="n">test_image</span><span class="p">,</span>
                              <span class="n">test_label</span><span class="p">,</span> <span class="n">quiet</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">confidence</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>How does the trained MLP fare if we translate the image? Run the following cell several times and see if the MLP continues to classify the digit correctly.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">predict_and_report_from_image</span><span class="p">(</span><span class="n">MLP</span><span class="p">,</span> <span class="n">test_image</span><span class="p">,</span> <span class="n">test_label</span><span class="p">,</span>
                              <span class="n">jiggled</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">quiet</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">confidence</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p><em>Record your observations about how well the MLP performs against the translated images here. Why do you think the network is performing the way it does?</em></p>
<div class="section" id="id1">
<h4>Example discussion<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h4>
<p><em>Click on the arrow in the sidebar or run this cell to reveal an example discussion.</em></p>
<p>When I tested the network against the translated/jiggled images, I found that it wasn’t very reliable at classifying them.</p>
<p>Although the digits are the same size as the original digits, the original MLP has no real sense of how the pixels representing the digits relate to each other according to their <em>relative</em> location.</p>
<p>Instead, it is looking for pixels that overlap the pixels representing the digit that were presented in the original training set. If we translate the digit in the image frame, it may end up overlapping the pixels associated with the original location of another digit more than it overlaps the pixels associated with its own originally located image.</p>
</div>
</div>
</div>
<div class="section" id="creating-more-new-images-from-old-zooming-cropped-images">
<h2>4.3 Creating more new images from old – zooming cropped images<a class="headerlink" href="#creating-more-new-images-from-old-zooming-cropped-images" title="Permalink to this headline">¶</a></h2>
<p>Another way of transforming the cropped images is to magnify them back to the original image size. (The rescaling employs a digital filter that is used to interpolate new pixel values in the scaled image based on the pixel values in the cropped image. As such, it may introduce digital artefacts of its own into the scaled image.)</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">nn_tools.sensor_data</span> <span class="kn">import</span> <span class="n">crop_and_zoom_to_fit</span>

<span class="n">crop_zoomed_image</span> <span class="o">=</span> <span class="n">crop_and_zoom_to_fit</span><span class="p">(</span><span class="n">test_image</span><span class="p">)</span>

<span class="n">zoom_img</span><span class="p">(</span> <span class="n">crop_zoomed_image</span> <span class="p">)</span>

<span class="c1"># Show size</span>
<span class="n">crop_zoomed_image</span><span class="o">.</span><span class="n">size</span>
</pre></div>
</div>
</div>
</div>
<p>To simplify the process of applying these transformations to a test image, we can call the <code class="docutils literal notranslate"><span class="pre">predict_and_report_from_image()</span></code> function with the <code class="docutils literal notranslate"><span class="pre">jiggled=True</span></code> and <code class="docutils literal notranslate"><span class="pre">cropzoom=True</span></code> parameters:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Test a jiggled version of the provided image</span>
<span class="n">predict_and_report_from_image</span><span class="p">(</span><span class="n">MLP</span><span class="p">,</span> <span class="n">test_image</span><span class="p">,</span> <span class="n">test_label</span><span class="p">,</span>
                              <span class="n">jiggled</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">quiet</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="c1"># Test a cropped and then zoomed version of the provided image</span>
<span class="n">predict_and_report_from_image</span><span class="p">(</span><span class="n">MLP</span><span class="p">,</span>
                              <span class="n">test_image</span><span class="p">,</span> <span class="n">test_label</span><span class="p">,</span>
                              <span class="n">cropzoom</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">quiet</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
<p>You can also pass the <code class="docutils literal notranslate"><span class="pre">zoomview=True</span></code> parameter to view the image at a larger scale.</p>
<div class="section" id="activity-rescaling-the-digit-within-the-image-frame">
<h3>4.3.1 Activity – Rescaling the digit within the image frame<a class="headerlink" href="#activity-rescaling-the-digit-within-the-image-frame" title="Permalink to this headline">¶</a></h3>
<p>How well does the trained MLP work if we rescale the image by cropping it and then zooming it to fit the original image size?</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">predict_and_report_from_image</span><span class="p">(</span><span class="n">MLP</span><span class="p">,</span>
                              <span class="n">test_image</span><span class="p">,</span> <span class="n">test_label</span><span class="p">,</span>
                              <span class="n">cropzoom</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">quiet</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">confidence</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p><em>Record your observations about how well the MLP performs against the translated images here. Why do you think the network is performing the way it does?</em></p>
<div class="section" id="id2">
<h4>Example discussion<a class="headerlink" href="#id2" title="Permalink to this headline">¶</a></h4>
<p><em>Click on the arrow in the sidebar or run this cell to reveal an example discussion.</em></p>
<p>When I tested the network against the resized images, I found that it wasn’t very reliable at classifying them.</p>
<p>The original MLP has no real sense of how images are scaled across the presented image frame: it is looking for pixels that overlap the pixels representing the digits that were presented in the original training set.</p>
</div>
</div>
<div class="section" id="activity-testing-the-network-against-lots-of-jiggled-and-zoomed-images">
<h3>4.3.2 Activity – Testing the network against lots of jiggled and zoomed images<a class="headerlink" href="#activity-testing-the-network-against-lots-of-jiggled-and-zoomed-images" title="Permalink to this headline">¶</a></h3>
<p>Run various combinations of the following test code to see how well the network behaves when tested against lots of transformed images. How well does it perform?</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">test_and_report_random_images</span><span class="p">(</span><span class="n">MLP</span><span class="p">,</span> 
                              <span class="n">get_random_image</span><span class="p">,</span> <span class="n">images_array</span><span class="o">=</span><span class="n">images_list</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">labels</span><span class="p">,</span>
                              <span class="n">num_samples</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">jiggled</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">cropzoom</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>## 4.4 Training the network on transformed images</p>
<p>The MNIST images we have been provided with each have dimensions of 28 × 28 pixels. If we want to try to classify a handwritten digit image using the MLP trained against these MNIST images, we need to resize the image to the same size.</p>
<p>In a later notebook, you will be using an MLP to try to classify handwritten digit images scanned in from the simulator. These image scans have size 14 × 14 pixels. If we were to resize those collected images and then present them to our network, the scaling up of the image may introduce digital artefacts that affect the classification.</p>
<p>So instead, let’s take the opportunity now to create an MLP trained on resized handwritten images, scaled down to a size of 14 × 14 pixels. This will further review the process of how we train an MLP.</p>
<p>To being with, let’s create a set of test images. The test images will be created using the following pipeline:</p>
<ul class="simple">
<li><p>generate an image from the image array data</p></li>
<li><p>resize the image from 28 × 28 pixels down to 14 × 14 pixels</p></li>
<li><p>convert the resized image to a black-and-white image using a specified threshold.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">nn_tools.network_views</span> <span class="kn">import</span> <span class="n">resized_images_pipeline</span>

<span class="n">resized_images</span> <span class="o">=</span> <span class="n">resized_images_pipeline</span><span class="p">(</span><span class="n">images_list</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">14</span><span class="p">,</span> <span class="mi">14</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<p>Now create the initial network architecture. We have simplified the data both by reducing the dimensions of the images (and hence the number of input nodes required) and also moved away from a discrete greyscale image representation to a binary black-and-white image representation.</p>
<p>So let’s use a simpler network.</p>
<p>Let’s try with just a single layer of 10 neurons to start with. We can use the <code class="docutils literal notranslate"><span class="pre">quick_progress_tracked_training()</span></code> function to provide a simple way of creating an MLP and tracking its training progress:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">nn_tools.network_views</span> <span class="kn">import</span> <span class="n">quick_progress_tracked_training</span>


<span class="n">hidden_layer_sizes</span> <span class="o">=</span> <span class="p">(</span><span class="mi">20</span><span class="p">)</span>
<span class="n">max_iterations</span> <span class="o">=</span> <span class="mi">150</span>


<span class="n">test_limit</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">train_limit</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">resized_images</span><span class="p">)</span> <span class="o">-</span> <span class="n">test_limit</span>


<span class="n">resized_training_images</span> <span class="o">=</span> <span class="n">resized_images</span><span class="p">[:</span><span class="n">train_limit</span><span class="p">]</span>
<span class="n">training_labels</span> <span class="o">=</span> <span class="n">labels</span><span class="p">[:</span><span class="n">train_limit</span><span class="p">]</span>

<span class="n">resized_testing_images</span> <span class="o">=</span> <span class="n">resized_images</span><span class="p">[</span><span class="n">train_limit</span><span class="p">:]</span>
<span class="n">testing_labels</span> <span class="o">=</span> <span class="n">labels</span><span class="p">[</span><span class="n">train_limit</span><span class="p">:]</span>

<span class="n">MLP2</span> <span class="o">=</span> <span class="n">quick_progress_tracked_training</span><span class="p">(</span><span class="n">resized_training_images</span><span class="p">,</span> <span class="n">training_labels</span><span class="p">,</span>
                                 <span class="n">hidden_layer_sizes</span><span class="o">=</span><span class="n">hidden_layer_sizes</span><span class="p">,</span>
                                 <span class="c1"># top up an existing reptrained MLP: MLP=MLP,</span>
                                 <span class="n">max_iterations</span><span class="o">=</span><span class="n">max_iterations</span><span class="p">,</span>
                                 <span class="n">loss</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="c1"># show loss function</span>
                                 <span class="n">structure</span><span class="o">=</span><span class="kc">True</span> <span class="c1"># show network params</span>
                                <span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p><em>Record your observations here about how well the MLP performs during training.</em></p>
<p>How well does the network perform on the unseen test samples?</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">nn_tools.network_views</span> <span class="kn">import</span> <span class="n">test_and_report_image_data</span>
<span class="kn">from</span> <span class="nn">nn_tools.sensor_data</span> <span class="kn">import</span> <span class="n">get_images_features</span>

<span class="n">resized_testing_data</span> <span class="o">=</span> <span class="n">get_images_features</span><span class="p">(</span><span class="n">resized_testing_images</span><span class="p">,</span> <span class="n">normalise</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">test_and_report_image_data</span><span class="p">(</span><span class="n">MLP2</span><span class="p">,</span> <span class="n">resized_testing_data</span><span class="p">,</span> <span class="n">testing_labels</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p><em>Record your observations here about how well the network performs on the previously unseen data.</em></p>
<p>How well does this network perform on jiggled images?</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">test_and_report_random_images</span><span class="p">(</span><span class="n">MLP2</span><span class="p">,</span> 
                              <span class="n">get_random_image</span><span class="p">,</span> <span class="n">images_array</span><span class="o">=</span><span class="n">resized_testing_images</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">testing_labels</span><span class="p">,</span>
                              <span class="n">num_samples</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">jiggled</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">cropzoom</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p><em>Record your observations here about how well the network performs when tested with the jiggled image data.</em></p>
<p>When I tried, it appeared not to perform very well at all with the jiggled images.</p>
<p>Let’s save this network:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">joblib</span> <span class="kn">import</span> <span class="n">dump</span>

<span class="c1"># Save the network</span>
<span class="n">dump</span><span class="p">(</span><span class="n">MLP2</span><span class="p">,</span> <span class="s1">&#39;mlp_mnist14x14.joblib&#39;</span><span class="p">)</span> 
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="rapidly-training-the-mlp">
<h3>4.4.1 Rapidly training the MLP<a class="headerlink" href="#rapidly-training-the-mlp" title="Permalink to this headline">¶</a></h3>
<p>Use the following <code class="docutils literal notranslate"><span class="pre">ipywidgets</span></code> application to easily try out different network structures when training the MLP using the resized image training data.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Train the network</span>

<span class="kn">from</span> <span class="nn">ipywidgets</span> <span class="kn">import</span> <span class="n">interact_manual</span>

<span class="n">MLP3</span><span class="o">=</span><span class="kc">None</span>

<span class="nd">@interact_manual</span><span class="p">(</span><span class="n">iterations</span><span class="o">=</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">2000</span><span class="p">,</span> <span class="mi">100</span><span class="p">),</span>
          <span class="n">h1</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">h2</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="k">def</span> <span class="nf">trainer</span><span class="p">(</span><span class="n">iterations</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">h1</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span> <span class="n">h2</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span> <span class="n">updater</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="k">global</span> <span class="n">MLP3</span>
    <span class="n">MLP3</span> <span class="o">=</span> <span class="n">quick_progress_tracked_training</span><span class="p">(</span><span class="n">resized_training_images</span><span class="p">,</span> <span class="n">training_labels</span><span class="p">,</span>
                                 <span class="n">hidden_layer_sizes</span><span class="o">=</span><span class="n">hidden_layer_sizes</span><span class="p">,</span>
                                 <span class="n">max_iterations</span><span class="o">=</span><span class="mi">40</span><span class="p">,</span>
                                 <span class="n">MLP</span> <span class="o">=</span> <span class="n">MLP3</span> <span class="k">if</span> <span class="n">updater</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span>
                                 <span class="n">loss</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="c1"># show loss function</span>
                                 <span class="n">structure</span><span class="o">=</span><span class="kc">True</span> <span class="c1"># show network params</span>
                                <span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Test the new network using the previously unseen test data:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">test_and_report_image_data</span><span class="p">(</span><span class="n">MLP3</span><span class="p">,</span> <span class="n">resized_testing_data</span><span class="p">,</span> <span class="n">testing_labels</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p><em>Feel free to experiment with training and testing the network using different setups. But don’t spend too much time playing!</em></p>
<p><em>Record any notes and observations you care to make about your experimentation here.</em></p>
<p>Save the trained network:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">dump</span><span class="p">(</span><span class="n">MLP3</span><span class="p">,</span> <span class="s1">&#39;resized_images_MLP.joblib&#39;</span><span class="p">)</span> 
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="summary">
<h2>4.5 Summary<a class="headerlink" href="#summary" title="Permalink to this headline">¶</a></h2>
<p>In this notebook, you have seen how we can create synthetic training data derived from the original dataset, in particular by cropping the original handwritten digits and then translating them to a new location within the original 28 × 28 pixel image frame, or zooming the cropped image to fit the original image frame.</p>
<p>You also saw how we can create a derived dataset from the original images consisting of images in a smaller image frame (14 × 14 rather than 28 × 28 pixels) and then train a new MLP on that. As a result of reducing the number of input features, we could also get away with using a smaller neural network to recognise the supplied images.</p>
<p>On testing the original MNIST data trained network against the translated and zoomed images, you also saw how the network performance was considerably degraded.</p>
<p>In the next notebook, you will learn how we can improve the network’s performance by finding a new way of presenting the images to the network using many fewer, but far more relevant, input features.</p>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./07. Neural networks"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            
                <!-- Previous / next buttons -->
<div class='prev-next-area'> 
    <a class='left-prev' id="prev-link" href="07.3%20Training%20an%20MLP%20using%20MNIST%20handwritten%20digit%20data.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">3 Training an MLP using MNIST handwritten digit data</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="07.5%20Feature%20engineering%20%28optional%29.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">5 Feature engineering (optional)</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            
        </div>
    </div>
    <footer class="footer">
  <p>
    
      By The Jupyter Book community<br/>
    
        &copy; Copyright 2021.<br/>
  </p>
</footer>
</main>


      </div>
    </div>
  
  <script src="../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>