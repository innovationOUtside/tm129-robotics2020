
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>6 Inside the mind of a neural network &#8212; TM129 Robotics Practical Activities</title>
    
  <link href="../_static/css/theme.css" rel="stylesheet" />
  <link href="../_static/css/index.c5995385ac14fb8791e8eb36b4908be2.css" rel="stylesheet" />

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/sphinx-book-theme.e8e5499552300ddf5d7adccae7cc3b70.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.1c5a1a01449ed65a7b51.js">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.12a9622fbb08dcb3a2a40b2c02b83a57.js"></script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="7 Using a convolutional neural network to recognise images (optional)" href="07.7%20Convolutional%20neural%20networks%20%28optional%29.html" />
    <link rel="prev" title="5 Feature engineering (optional)" href="07.5%20Feature%20engineering%20%28optional%29.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
      
      <h1 class="site-logo" id="site-title">TM129 Robotics Practical Activities</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../README_FIRST.html">
   Welcome to the TM129 Robotics block
  </a>
 </li>
</ul>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../00_FOR_VLE/Section_00_01_Introduction.html">
   1 Introduction
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../00_NOTES_FOR_TUTORS/GETTING_STARTED.html">
   Getting started
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../01.%20Introducing%20notebooks%20and%20the%20RoboLab%20environment/01.1%20Jupyter%20environment.html">
   1 Introduction to the TM129 Jupyter notebook environment
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../01.%20Introducing%20notebooks%20and%20the%20RoboLab%20environment/01.2%20Exploring%20the%20notebook%20environment.html">
     2 The interactive read-writable notebook environment
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../01.%20Introducing%20notebooks%20and%20the%20RoboLab%20environment/01.3%20Introducing%20nbev3devsim.html">
     3 The RoboLab simulated on-screen robot (
     <code class="docutils literal notranslate">
      <span class="pre">
       nbev3devsim
      </span>
     </code>
     )
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../01.%20Introducing%20notebooks%20and%20the%20RoboLab%20environment/01.4%20Exploring%20nbev3devsim.html">
     4 Exploring the
     <code class="docutils literal notranslate">
      <span class="pre">
       nbev3devsim
      </span>
     </code>
     simulator
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../01.%20Introducing%20notebooks%20and%20the%20RoboLab%20environment/01.5%20Example%20robot%20program.html">
     5 An example robot program
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../01.%20Introducing%20notebooks%20and%20the%20RoboLab%20environment/01.6%20Working%20With%20Simulators.html">
     6 Working with simulators
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../02.%20Getting%20started%20with%20robot%20and%20Python%20programming/02.1%20Robot%20programming%20constructs.html">
   1 An introduction to programming robots
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../02.%20Getting%20started%20with%20robot%20and%20Python%20programming/02.2%20Creating%20your%20own%20robot%20programs.html">
     2 Creating your own robot programs
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../02.%20Getting%20started%20with%20robot%20and%20Python%20programming/02.3%20General%20programming%20concepts.html">
     3.1 Constants and variables in programs
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../02.%20Getting%20started%20with%20robot%20and%20Python%20programming/02.4%20Getting%20started%20with%20sensors.html">
     4 Robot sensors and data logging
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../03.%20Controlling%20program%20execution%20flow/03.1%20Program%20control%20using%20for%20loops.html">
   1 Introduction to program control flow
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../03.%20Controlling%20program%20execution%20flow/03.2%20Program%20control%20using%20while%20loops%20and%20blocking.html">
     2 Program control flow using a
     <code class="docutils literal notranslate">
      <span class="pre">
       while...
      </span>
     </code>
     loop
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../03.%20Controlling%20program%20execution%20flow/03.3%20Program%20control%20flow%20using%20branches.html">
     3 Branches
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../03.%20Controlling%20program%20execution%20flow/03.4%20Example%20robot%20control%20programs.html">
     4 Example robot control programs
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../03.%20Controlling%20program%20execution%20flow/03.5%20Some%20RoboLab%20challenges.html">
     5 RoboLab challenges
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../03.%20Controlling%20program%20execution%20flow/03.6%20Optional%20RoboLab%20challenges.html">
     6 Optional challenges
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../04.%20Not%20quite%20intelligent%20robots/04.1%20Introducing%20program%20functions.html">
   1 Introduction to functions and robot control strategies
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../04.%20Not%20quite%20intelligent%20robots/04.2%20Robot%20navigation%20using%20dead%20reckoning.html">
     2 Dead reckoning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../04.%20Not%20quite%20intelligent%20robots/04.3%20Emergent%20robot%20behaviour%20and%20simple%20data%20charts.html">
     3 Emergent robot behaviour and simple data charts
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../04.%20Not%20quite%20intelligent%20robots/04.4%20Reasoning%20with%20Eliza.html">
     4 Reasoning with Eliza
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../04.%20Not%20quite%20intelligent%20robots/04.5%20Reasoning%20with%20rule%20based%20systems.html">
     5 Reasoning with rule-based systems – Durable Rules Engine
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../05.%20Experimenting%20with%20sensors/05.1%20Introducing%20sensor%20based%20control.html">
   Introduction to sensor-based control
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../06.%20Where%20in%20the%20world%20are%20we/06.1%20Introducing%20sensor%20based%20navigation.html">
   Introducing sensor-based navigation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="07.1%20Introducing%20neural%20networks.html">
   1 Introducing neural networks
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../08.%20Remote%20services%20and%20multi-agent%20systems/08.1%20Introducing%20remote%20services%20and%20multi-agent%20systems.html">
   1 An introduction to remote services and multi-agent systems
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
  <label for="toctree-checkbox-5">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../08.%20Remote%20services%20and%20multi-agent%20systems/08.2%20Collecting%20digit%20image%20and%20class%20data%20from%20the%20simulator.html">
     2 Collecting digit image and class data from the simulator
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../08.%20Remote%20services%20and%20multi-agent%20systems/08.3%20Recognising%20digits%20using%20a%20convolutional%20neural%20network%20%28optional%29.html">
     3 Recognising digits using a convolutional neural network (optional)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../08.%20Remote%20services%20and%20multi-agent%20systems/08.4%20Recognising%20patterns%20on%20the%20move.html">
     4 Recognising patterns on the move
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../08.%20Remote%20services%20and%20multi-agent%20systems/08.5%20Messaging%20in%20multi-agent%20systems.html">
     5 Messaging in multi-agent systems
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../08.%20Remote%20services%20and%20multi-agent%20systems/08.6%20Conclusion.html">
     6 Conclusion
    </a>
   </li>
  </ul>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/07. Neural networks/07.6 Inside the mind of a neural network.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/executablebooks/jupyter-book/master?urlpath=tree/07. Neural networks/07.6 Inside the mind of a neural network.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#introducing-the-tensorflow-playground">
   6.1 Introducing the TensorFlow Playground
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#activity-a-harder-example-xor">
     6.1.1 Activity – A harder example: XOR
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#optional-activity-manually-editing-weights">
     6.1.2 Optional activity – Manually editing weights
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#yet-more-complicated-patterns">
   6.2 Yet more complicated patterns
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#summary">
   6.3 Summary
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="inside-the-mind-of-a-neural-network">
<h1>6 Inside the mind of a neural network<a class="headerlink" href="#inside-the-mind-of-a-neural-network" title="Permalink to this headline">¶</a></h1>
<p>In the previous required notebook, you met a simple neural network architecture known as a <em>multi-layer perceptron</em> and saw how it could be trained to recognise and distinguish between various classes of object based on a two-dimensional representation of each object.</p>
<p>You also saw how we could inspect the weights of a network, as well as map the decision boundaries that it created in order to distinguish the different classes.</p>
<p>To a certain extent, training neural networks effectively is a creative act in which the network designer explores various combinations of feature design, network architecture and training regime to create a network capable of performing a desired task.</p>
<p>In this notebook, you will use a tool originally published as the <em>TensorFlow Playground</em> to explore how a neural network distinguishes between two classes of input that are arranged in a way that cannot be separated by drawing simple lines between them.</p>
<div class="section" id="introducing-the-tensorflow-playground">
<h2>6.1 Introducing the TensorFlow Playground<a class="headerlink" href="#introducing-the-tensorflow-playground" title="Permalink to this headline">¶</a></h2>
<p>We’ll start with a simple activity to introduce you to some of the playground controls.</p>
<p>The minimal interface looks like this:</p>
<p><img alt="Tensorflow playground minimal UI" src="../_images/tensorflow_playground_simple.png" /></p>
<p>On the left-hand side are several test datasets: these are datasets we can train the network on. The datasets are represented as points in a two-dimensional space over the range <code class="docutils literal notranslate"><span class="pre">-1</span> <span class="pre">...</span> <span class="pre">+1</span></code> on each axis. For our introductory activity, we’ll use the dataset with two clear clusters of points: a cluster of orange points in the bottom left of the two-dimensional test area, and a cluster of points in the top right.</p>
<p>In the middle, we have the network, in this case with two input neurons, and a single hidden layer with a single neuron. The hidden layer neuron is connected to an output display that shows the training data and the discrimination that has been applied to it in a view similar to the boundary line visualisation in the previous notebook.</p>
<p>If you hover over a node in the network – either the input layer or one of the hidden layer – then you will see the discrimination made by that node previewed in the larger output view.</p>
<p>The inputs to the network are defined as <em>features</em>. The first feature corresponds to the <em>x</em>-coordinate in the training data, and is labelled <span class="math notranslate nohighlight">\(X_1\)</span> in the original TensorFlow Playground. The second feature corresponds to the <em>y</em>-coordinate, and is labelled <span class="math notranslate nohighlight">\(X_2\)</span> in the original TensorFlow Playground. The depiction inside the node resembles the boundary decision visualisation; in the first input node, the negative <em>x</em>-values are coloured one way and the positive <em>x</em>-values another; in the second input node, the negative <em>y</em>-values are coloured one way and the positive <em>y</em>-values another.</p>
<p>You can launch an interactive version of this configuration of the playground here: <a class="reference external" href="../../../nb_tensorflow_playground_serverproxy/#activation=tanh&amp;batchSize=10&amp;dataset=gauss%C2%AEDataset=reg-plane&amp;learningRate=0.03%C2%AEularizationRate=0&amp;noise=0&amp;networkShape=1&amp;seed=0.34237&amp;showTestData=false&amp;discretize=true&amp;percTrainData=50&amp;x=true&amp;y=true&amp;xTimesY=false&amp;xSquared=false&amp;ySquared=false&amp;cosX=false&amp;sinX=false&amp;cosY=false&amp;sinY=false&amp;collectStats=false&amp;problem=classification&amp;initZero=false&amp;hideText=false&amp;noise_hide=true&amp;batchSize_hide=true&amp;dataset_hide=false&amp;numHiddenLayers_hide=false&amp;percTrainData_hide=true%C2%AEularizationRate_hide=true&amp;learningRate_hide=true&amp;problem_hide=true%C2%AEularization_hide=true&amp;activation_hide=true">Tensorflow Playground - simple patter recogniser</a>.</p>
<p><strong>If the direct link does not work for you, then from the notebook home page open the <code class="docutils literal notranslate"><span class="pre">New</span></code> menu and select the <code class="docutils literal notranslate"><span class="pre">nb_tensorflow_playground_serverproxy</span></code> option.</strong></p>
<!-- JD: the direct link didn't work for me when using Compute Home. -->
<p>If you click the reset button in the top left of the user interface, just to the left of the play button, then you will see that the view represented in the hidden node changes; the output view also changes as we change the random weights connecting the inputs to the hidden layer.</p>
<p>You can train the network by clicking the play button, which toggles to display a stop button as the network trains. As the network is trained, you will see the weights change thickness and colour, depicting the magnitude and sign (positive or negative) of the weight respectively. A dynamically updated line chart in the top right of the playground shows the ‘error’ value, a measure that decreases as the network improves its ability to correctly detect which class an input is in. To stop the network training, you need to click the stop button to toggle it back to show the play button.</p>
<p>This network trains quite quickly, and you will see that even the single neuron can detect which of the two classes each of our test inputs falls into.</p>
<p>In the playground, you will also notice a checkbox that allows you to ‘discretize’ the output. This allows us to force the output to decide explicitly which group it thinks a point falls into, rather than hedging its bets (‘probably the orange group’, ‘maybe the blue group’, ‘erm, the orange group I think, maybe..?’).</p>
<p>The <em>Show test data</em> checkbox will show you the data used to test the output of the network. This is data that the network does not see whilst it is being trained.</p>
<div class="section" id="activity-a-harder-example-xor">
<h3>6.1.1 Activity – A harder example: XOR<a class="headerlink" href="#activity-a-harder-example-xor" title="Permalink to this headline">¶</a></h3>
<p>In the initial example, we could separate the two clusters with a single line, implemented by a single neuron.</p>
<p>Change the dataset to the ‘XOR’ (exclusive or) dataset. This shows test cases in one group (that is, one colour) if the <em>x</em>- and <em>y</em>-values are both negative or both positive, and the other group (the other colour) if the <em>x</em>- and <em>y</em>-values have different signs.</p>
<img src="../images/tensorflow_playground_xor.png" width=200px />
<p>Reset the single hidden node neuron and retrain the network. Can it distinguish the two groups this time?</p>
<p>Add a second node to the single hidden layer, reset the network, and try again. Can the network distinguish between the two groups?</p>
<p><em>Can your network distinguish the two groups using just a single layer? If so, how many neurons are required? What do you notice about the shape of the boundary line visualisation as you increase the number of hidden neurons:</em></p>
<p><em>(a) as the network is trained?</em></p>
<p><em>(b) when the network is trained as well as it can be?</em></p>
<p>Take the size of the network back to a single hidden layer with just one neuron, then add a second hidden layer again with a single hidden neuron. Train the network. Does it solve the classification task?</p>
<p><em>What is the smallest combination of nodes across the two layers that will solve the classification problem reliably? Does the second hidden layer help at all?</em></p>
<p><em>What is the smallest combination of nodes across three hidden layers that can solve the task? How about four layers? Or five?</em></p>
<p><em>When the network reaches a steady state, do you observe anything notable about the boundary lines it has learned for differing numbers and combinations of neurons across the hidden layers?</em></p>
<p><strong>Note that as you increase the number of layers, the network may take an increasing amount of time to find a steady, final state, as indicated by the error curve reaching a steady, flat state.</strong></p>
</div>
<div class="section" id="optional-activity-manually-editing-weights">
<h3>6.1.2 Optional activity – Manually editing weights<a class="headerlink" href="#optional-activity-manually-editing-weights" title="Permalink to this headline">¶</a></h3>
<p>As well as training the network to find weights that allow the network to make a decision, you can also hover over a weight and edit it manually.</p>
<p>Reset the network to a single hidden layer with five neurons and train it on the XOR dataset. Can you effectively disable one of the hidden neurons by setting its output weight to zero and still maintain its level of performance?</p>
<p>Now pick one of the other neurons. Select one of its weights and watch how the discrimination of the node it is input into changes, as well as the overall output. Can you get a feel for how the behaviour of the node you are changing the input weight(s) to will change as you alter the weight? Can you get a feel for how the overall output decision will change as a result?</p>
<p>Sometimes, you may find that you can just about predict how a network is coming to a decision based on the decision a node makes, or the decision it makes based on a combination of inputs from a previous layer and the decision they appear to be making. At other times, particularly as the network gets more complex, you may feel as if you have no idea at all about how it is making its decisions.</p>
<p><em>Add any notes and reflections you care to make here.</em></p>
</div>
</div>
<div class="section" id="yet-more-complicated-patterns">
<h2>6.2 Yet more complicated patterns<a class="headerlink" href="#yet-more-complicated-patterns" title="Permalink to this headline">¶</a></h2>
<p>From experimenting with the TensorFlow Playground, you may have started to realise that the network makes its decisions by essentially trying to draw some combination of straight lines across the feature space to separate the groups.</p>
<p>If you look at the available training datasets, then you will see two more, rather trickier examples: one that contains two interlaced groups forming a spiral shape; and the other containing a central, circular clustered group inside a circular ring doughnut shape created by the other.</p>
<p>If you have not spent too much time on this notebook already, or if perhaps you fancy a play over a coffee break at some other time, see if you can create a network that can separate these groups. Don’t spend too much time on it though! (It can get quite addictive when you try…)</p>
<p>If you find an architecture that appears to work well without too many underused neurons (particularly low sets of input and/or output weights) across multiple resets (i.e. reset initial weights and training runs), then share the details on your Cluster group forum and put those who haven’t had as much luck out of their misery!</p>
<p>Note that if you have a network with a large number of hidden neurons, sometimes the boundary lines the trained network generates seem to try to fit round the data ‘too well’ (that is, the boundary line shape gets very wiggly around certain points to take account of them). This is known as ‘overfitting’ and causes the network to generalise less well: that is, when presented with a pattern it has not seen before, it can’t broadly, or ‘generally’, see which group it is likely to fall into based on its training.</p>
<p>If you take the OU module TM358 <em>Machine learning and artificial intelligence</em>, which looks at machine-learning techniques in more depth, then you will learn in much more detail about neural network pathologies such as overfitting.</p>
</div>
<div class="section" id="summary">
<h2>6.3 Summary<a class="headerlink" href="#summary" title="Permalink to this headline">¶</a></h2>
<p>In this notebook, you used the TensorFlow Playground to learn how to separate out two different groups of items that were arranged in different ways in the two-dimensional feature space. Whilst the groups were easily separable to the human eye, they provided more of challenge to the network.</p>
<p>Increasing the number of hidden nodes, both within a single layer and sometimes across multiple layers, allows the nodes to combine their individual decisions into a single weighted decision about what output group a particular pattern is in. If the network is too complicated for the task at hand, then it may start to lose the ability to generalise as a result of ‘overfitting’ the model to the data the network was trained on.</p>
<p>The final notebook is optional and explores several techniques for visualising the structure and behaviour of convolutional networks in an interactive way.</p>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./07. Neural networks"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        
        <div class='prev-next-bottom'>
            
    <a class='left-prev' id="prev-link" href="07.5%20Feature%20engineering%20%28optional%29.html" title="previous page">5 Feature engineering (optional)</a>
    <a class='right-next' id="next-link" href="07.7%20Convolutional%20neural%20networks%20%28optional%29.html" title="next page">7 Using a convolutional neural network to recognise images (optional)</a>

        </div>
        
        </div>
    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By The Jupyter Book community<br/>
        
            &copy; Copyright 2021.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>
  
  <script src="../_static/js/index.1c5a1a01449ed65a7b51.js"></script>

  
  </body>
</html>