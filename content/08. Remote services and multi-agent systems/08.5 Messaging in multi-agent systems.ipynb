{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 Messaging in multi-agent systems\n",
    "\n",
    "In the previous notebooks in this session, you have seen how we can pull data collected in the simulator into the notebook's Python environment, and then analyse it in that environment at our convenience.\n",
    "\n",
    "In particular, we could convert the raw data to an image-based representation, as well as presenting it as raw data to a pre-trained multi-layer perceptron (MLP) or a pre-trained convolutional neural network (CNN).\n",
    "\n",
    "We could also capture and decode test labels for the images, allowing us to train a classifier neural network purely using information retrieved from the simulated robot.\n",
    "\n",
    "To simplify data collection matters in the original experiments, we \"teleported\" the robot to specific sampling locations, rather than expecting it to explore the environment and try to detect images on its own.\n",
    "\n",
    "In the previous notebook, you saw how we could collect data \"on the move\", getting the robot to drive over a set of test images and collecting the data as it did so. We then retrieved this data from a synchronised datalog in the Python environment when we had completed the data collection activity.\n",
    "\n",
    "In this notebook, we will try to make things even more dynamic. In particular, we will make use of a communication mechanism where the robot can send data back to the notebook environment for analysis. When the analysis is complete, a message will then be sent from the notebook Python environment back to the robot identifying how the supposed image was classified."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 ROS â€” the Robot Operating System\n",
    "\n",
    "*ROS*, the *Robot Operating System*, provides one possible architecture for implementing a dynamic message-passing architecture. In a ROS environment, separate *nodes* publish details of one or more *services* they can perform along with *topics* that act as the nodes address that other nodes can subscribe to. Nodes then pass messages between each other in order to perform a particular task. The ROS architecture is rather elaborate for our needs, however, so we shall use a much simpler and more direct approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "alert-success"
    ]
   },
   "source": [
    "*How messages are exchanged is governed by a `protocol` that defines what the messages mean, and how the agents should take turns in sending and receiving.*\n",
    "\n",
    "*The protocol should also handle cases where messages get lost, since no communication channel is fully reliable. For example, infrared messages could be lost if the robot wanders out of range or just faces the wrong way.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The approach we will use, although a much simpler approach than the full ROS architecture, will also be based on a message-passing approach. To implement the communication system, we need to define a \"message\" handler in the notebook's Python environment that can accept messages sent from the simulated robot, perform some sort of analysis task on the received data, and then provide a response back to the simulated robot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.1 Communicating between the notebook and the robot\n",
    "\n",
    "A simple diagram helps to explain the architecture we are using.\n",
    "\n",
    "We'll create the diagram using the `%%blockdiag` magic you met previously. Let's load it in and enable it first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext blockdiag_magic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the written image description in the following code cell, can you visualise in your mind's eye what the simplified architecture looks like?\n",
    "\n",
    "Run the following cell to generate the image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%blockdiag\n",
    "\n",
    "robot [label = \"Robot\"];\n",
    "python [label = \"Python message\\nhandler\"];\n",
    "mlp [label = \"Neural network\"];\n",
    "\n",
    "\n",
    "\n",
    "robot <-> python <-> mlp;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The diagram shows three boxes:\n",
    "\n",
    "- the first box, labeled *Robot*, is connected by a double-headed arrow to the second box, labeled *Python message handler*; (the `\\n` character in the second label represents a line break)\n",
    "- the second box is connected by another double-headed arrow to the third box, labelled *Neural network*.\n",
    "\n",
    "The figure is intended to convey the idea that the robot sends a message to a message handler running in the notebook's Python environment, which presents the decoded message contents to a neural network. The network classifies the data, passes the classification \"back\" to the message handler, and this in turn passes a response message back to the simulated robot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.2  Defining a simple message handler\n",
    "\n",
    "Inside the robot, a simple mechanism is already defined that allows the robot to send a message to the Python environment, but there is nothing defined on the Python end to handle it.\n",
    "\n",
    "To set it up, load the simulator in the normal way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the simulator\n",
    "from nbev3devsim.load_nbev3devwidget import roboSim, eds\n",
    "%load_ext nbev3devsim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the settings menu in the simulator, enable the *Collaborative* option. Alternatively, use the `--collab / -L` magic flag:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sim_magic --collab -HWZ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enabling the *Collaborative* mode means that when messages are printed to the simulator output window prefixed by the label `PY::`, they are also passed to the Python environment.\n",
    "\n",
    "We can create custom handlers on the Python notebook side that can pick up messages sent from the simulator and return a response to the simulator.\n",
    "\n",
    "We do this in three steps.\n",
    "\n",
    "First, we define a function that can *parse* messages sent from the robot. We can use a *regular expression* to help us parse the original message (`re.search()`), and then use a very unsafe method (`eval()`) to try to parse the message as a Python data structure.\n",
    "\n",
    "*You are not expected to be able to create your own regular expressions in order to successfully complete the module.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def simple_parser(msg):\n",
    "    \"\"\"Simple message parser.\"\"\"\n",
    "    # Match messages that start \"PY::\"\n",
    "    match = re.search(r'^PY::(.+)', msg)\n",
    "    if match:\n",
    "        matches = match.groups()\n",
    "        # Get the matched text string\n",
    "        match_str = matches[0]\n",
    "        # Try to cast it to a Python object\n",
    "        # Note - this is very insecure and not\n",
    "        # a secure thing to do!\n",
    "        try:\n",
    "            obj = eval(match_str)\n",
    "        except:\n",
    "            obj = match_str\n",
    "        return obj\n",
    "    # No match, so return None\n",
    "    return None\n",
    "\n",
    "parser = simple_parser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "alert-success"
    ]
   },
   "source": [
    "*Regular expression pattern matchers capable of matching particular string patterns are found in many programming languages.*\n",
    "\n",
    "*Regular expressions use a special vocabulary of terms for matching string elements, including `^` to represent the start of a string, `.` to represent any character, `+` to represent one or more of the preceding character, and ` * ` to represent zero or more of the preceding character. Bracketed items can be \"captured\" into matched groups.*\n",
    "\n",
    "*Covering regular expressions in any further detail is outside the scope of this module.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "activity": true
   },
   "source": [
    "Run the following code cell to test the simple parser agent against various text messages. *Feel free to come up with your own test messages.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_messages = [\"PY::1\",\n",
    "                 \"PY::[1, 2, 3]\",\n",
    "                 \"PY:: {'int': 1, 'str': 'string'}\",\n",
    "                 \"PY::my message\",\n",
    "                 \"my message\"\n",
    "                 ]\n",
    "\n",
    "for msg in test_messages:\n",
    "    print(f'Original: {msg}')\n",
    "    if simple_parser(msg):\n",
    "        print(f'Parsed: {simple_parser(msg)}')\n",
    "        print(f'Type: {type(simple_parser(msg))}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the parser takes the message and then tries to parse it as Python objects where it can. This includes casting items to numerical integers, lists, dictionaries and, the final default type, strings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second, we need to define a `responder()` function. This function should accept a message object, parse it, do something with it, and provide a response.\n",
    "\n",
    "We'll also add an ability to log what the Python side sees and return it in a log file, `logger.txt`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "alert-warning"
    ]
   },
   "source": [
    "*The `seqdiag` block magic is of a similar kind to the `blockdiag` magic and creates another diagram type, in this case a __sequence diagram__. The diagram shows how messages are passed in order between different actors in a communication system.*\n",
    "\n",
    "*Time starts at the top of the diagram and increases as you read down the diagram. The arrows show how messages pass from one actor to another. The increasing time dimension highlights the sequential order in which messages are passed.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our protocol will look something like the following (run the code cell to render the sequence diagram):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%seqdiag\n",
    "default_fontsize = 24;\n",
    "edge_length = 220;\n",
    "activation = none;\n",
    "\n",
    "robot  -> responder [label = \"PY::message\"];\n",
    "responder -> parser;\n",
    "responder <- parser;\n",
    "responder --> logger [label = \"log message\\nand response\"];\n",
    "robot <- responder [label = \"Python\\nsaw(message)\"];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the sequence diagram, the *robot* passes a message to the *responder*, which handles the message by passing it to a *parser*. The parsed message is returned to the *responder*, which creates an entry in a *logger* log file and sends a response back to the *robot*. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following command will clear the logfile if it has already been written to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile logger.txt\n",
    "# Responder logfile\n",
    "# -----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the responder itself, this might be as simple as returning a message that essentially echoes the parsed message passed to the function with a simple text wrapper: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logger(msg, response):\n",
    "    \"\"\"Create a simple logfile output.\"\"\"\n",
    "    # Log the response to a file\n",
    "    with open('logger.txt', 'a') as f:\n",
    "        f.write(f'Received message: {msg}\\n')\n",
    "        f.write(f'Response: {response}\\n')\n",
    "        f.write(f'---\\n')\n",
    "\n",
    "\n",
    "def echo_responder(msg_object):\n",
    "    \"\"\"Echo the original message in a simple message.\"\"\"\n",
    "    # Parse the message\n",
    "    msg = parser(msg_object)\n",
    "\n",
    "    # Do something with the message here...\n",
    "    response = f'Python saw >> {msg} << that...'\n",
    "\n",
    "    # Write to the logger\n",
    "    logger(msg, response)\n",
    "\n",
    "    # Return the response\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The third thing we need to do is configure the `roboSim` Python object to use the `responder()` function we have just defined as the message handler. This will handle messages sent from the simulated robot (that is, messages starting with `PY::` that are `print`ed to the output window with the simulator in *Collaborative* mode)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roboSim.pyresponder = echo_responder\n",
    "\n",
    "# Flush any garbage already on the line...\n",
    "%sim_magic --refresh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clear the logfile:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile logger.txt\n",
    "# Responder logfile\n",
    "# -----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we should be able to send messages from the robot to the Python environment, handle them on the Python side, and then send a response back to the robot. The message sent back to the robot is displayed in the output window:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sim_magic_preloaded -ROHW --collab\n",
    "import time\n",
    "\n",
    "for i in range(5):\n",
    "    \n",
    "    print(\"Robot says\", str(i))\n",
    "    if not i%2:\n",
    "        print(\"PY::\"+str(i))\n",
    "        \n",
    "    # We need some physical time to elapse\n",
    "    # to give time for the messages to propagate\n",
    "    time.sleep(1)\n",
    "\n",
    "say(\"all done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wait until the program has completed its run (you should hear it say *all done* at the end).\n",
    "\n",
    "If you now review the contents of the simulator output window, you can see how the robot starts by sending a message:\n",
    "\n",
    "`PY::0`\n",
    "\n",
    "and the Python process then responds:\n",
    "\n",
    "`Python saw >> 0 << that...`\n",
    "\n",
    "The robot then sends several further messages that the Python agent responds to appropriately."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also view the logfile to see a report from the Python side of the transaction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cat logger.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.3 Passing state\n",
    "\n",
    "Passing messages is all very well, but can we go a step further? Can we pass *data objects* between the robot and the Python environment, and back again?\n",
    "\n",
    "Let's start by adding another level of indirection to our program. In this case, let's create a simple agent that takes a parsed message object, does something to it (which in this case isn't very interesting!) and passes a modified object back:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_echo_agent(msg):\n",
    "    \"\"\"Simple echo agent.\"\"\"\n",
    "    \n",
    "    # Suppose we have a dictionary response\n",
    "    # Just echo that back\n",
    "    return f'Py saw: {msg}'\n",
    "\n",
    "agent = simple_echo_agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following responder works in the following way:\n",
    "\n",
    "- it parses a message received from the robot\n",
    "- it passes the parsed message to an agent, which does something with it\n",
    "- it gets a response back from the agent\n",
    "- it encodes the agent's response so that it can be used in our message protocol\n",
    "- it responds to the robot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%seqdiag\n",
    "default_fontsize = 24;\n",
    "edge_length = 220;\n",
    "\n",
    "activation = none;\n",
    "robot  -> responder [label = \"PY::message\"];\n",
    "responder -> agent -> parser [label='message'];\n",
    "agent <- parser [label='object'];\n",
    "responder <- agent [label='response'];\n",
    "responder --> logger [label = \"log message\\nand response\"];\n",
    "robot <- responder [label = \"JSON::response\"];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the sequence diagram, the *robot* passes a message to the *responder*, which passes it on the the *agent*. The agent gets the message parsed by the *parser* and passes a response object back to the *responder*. The *responder* creates a log entry and sends a response back to the *robot*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "alert-success"
    ]
   },
   "source": [
    "*JavaScript Object Notation (JSON)* is a text based format for serialising JavaScript objects as text strings. These text strings can be easily communicated over computer networks. JSON data is widely used to pass data between webservers and web browsers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's an implementation of the JavaScript Object Notation (JSON) message handling responder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def json_responder(msg_object):\n",
    "    \"\"\"Echo the original message as JSON.\"\"\"\n",
    "    # Pass the message to an agent who will\n",
    "    # parse the message, act on it and provide\n",
    "    # a response\n",
    "    agent_response = agent(parser(msg_object))\n",
    "    \n",
    "    # Get the agents response and wrap it as a message\n",
    "    json_data = {'message': agent_response}\n",
    "    \n",
    "    # Convert that object to a serialised\n",
    "    # JSON message (a text string)\n",
    "    json_string = json.dumps(json_data)\n",
    "    # On the robot side, we can parse this\n",
    "    # text message to recreate a JavaScript object\n",
    "\n",
    "    # Create a response that works with\n",
    "    # our message protocol\n",
    "    response = f\"JSON::{json_string}\"\n",
    "    \n",
    "    # Write to the logger\n",
    "    logger(msg, response)\n",
    "    \n",
    "    # Return the response\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how that message handler works on some test messages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_messages = [\"PY::my message\",\n",
    "                 \"PY:: [1,2,3]\",\n",
    "                 'PY::{\"key\": \"value\"}',\n",
    "                 \"my message\"]\n",
    "\n",
    "for msg in test_messages:\n",
    "    print(f'Original: {msg}')\n",
    "    if json_responder(msg):\n",
    "        print(f'Response: {json_responder(msg)}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, the parser returns a Python object to the responder, which creates a JSON string representation of it that can be passed back to the simulated robot as a simple text message."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's hook that responder up as a new responder to the robot's messages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roboSim.pyresponder = json_responder\n",
    "\n",
    "# Flush any garbage already on the line...\n",
    "%sim_magic --refresh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clear the logfile:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile logger.txt\n",
    "# Responder logfile\n",
    "# -----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try out our new responder and see if we can:\n",
    "\n",
    "- pass a JavaScript object from the robot, as a JSON string, to the Python environment\n",
    "- decode the string, do something with it, create a JSON-encoded response and send it back to the robot\n",
    "- parse the received message as a JavaScript object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sim_magic_preloaded -ROHW --collab\n",
    "import ev3dev2_glue as glue\n",
    "import time\n",
    "\n",
    "for i in range(5):\n",
    "    # The robot prints a message\n",
    "    # This will not be responded to\n",
    "    print(\"Robot says\", str(i))\n",
    "    \n",
    "    if not i%2:\n",
    "        # Display a message that is sent to Python\n",
    "        print(\"PY::\"+str(i))\n",
    "        # Any response will be displayed in\n",
    "        # the output display\n",
    "    \n",
    "    # The returned message is added to\n",
    "    # an internal message queue \n",
    "    msg_queue = glue.pyState()\n",
    "    print('Message queue', msg_queue)\n",
    "    time.sleep(1)\n",
    "\n",
    "msg_queue = glue.pyState()\n",
    "print('Message queue',msg_queue)\n",
    "print(\"Last message\", msg_queue[\"messages\"][-1])\n",
    "\n",
    "py_msg = str(msg_queue[\"messages\"][-1]['message'])\n",
    "say(\"Last Python message was ...\"+py_msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we run this program in the simulator, the robot sends a message such as:\n",
    "\n",
    "`PY::0`\n",
    "\n",
    "The Python agent receives the message and responds with a message of the form:\n",
    "\n",
    "`JSON::{\"message\": \"Py saw: 0\"}`\n",
    "\n",
    "The response is decoded by the robot as the JavaScript object `{\"message\": \"Py saw: 0\"}` and added to the end of a `messages` list. We can then access the messages as required."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we can also view the logfile giving the Python agent's perspective:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cat logger.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.4 Extending the message parser\n",
    "\n",
    "Let's now look at how we might retrieve real-time sensor data in our message-passing system.\n",
    "\n",
    "As well as the `PY::` message processor, the robot also has a special `IMG_DATA` message processor. Printing the message `IMG_DATA` to the simulator output window causes a special message to be passed to the Python environment. This message starts with the phrase `IMG_DATA::`, followed by the sensor data.\n",
    "\n",
    "We need to extend our parser to handle this message:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_parser(msg):\n",
    "    \"\"\"Simple message parser with image parsing support.\"\"\"\n",
    "    # Match messages that start \"PY::\" or \"IMG_DATA::\"\n",
    "    match = re.search(r'^(IMG_DATA|PY)::(.+)', msg)\n",
    "    if match:\n",
    "        matches = match.groups()\n",
    "        # Get the matched text string\n",
    "        # Try to cast it to a Python object\n",
    "        # Note - this is very insecure and not\n",
    "        # a secure thing to do!\n",
    "        match_str = matches[1]\n",
    "        try:\n",
    "            obj = eval(match_str)\n",
    "        except:\n",
    "            obj = match_str\n",
    "        return {'typ':matches[0], 'obj': obj}\n",
    "    \n",
    "    # No match, so return None\n",
    "    return None\n",
    "\n",
    "parser = image_parser\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's just test that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_messages = [\"PY::1\",\n",
    "                 \"PY::[1, 2, 3]\",\n",
    "                 \"PY:: {'int': 1, 'str': 'string'}\",\n",
    "                 \"PY::my message\",\n",
    "                 \"IMG_DATA::{'k1':[1,2,3], 'k2':[4,5,6]}\"\n",
    "                 ]\n",
    "\n",
    "for msg in test_messages:\n",
    "    print(f'Original: {msg}')\n",
    "    if parser(msg):\n",
    "        print(f'Parsed: {parser(msg)}')\n",
    "        print(f'Type: {type(parser(msg))}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe how our new `image_parser()` function can cope with the original `PY::` prefixed messages and the new `IMG_DATA::` prefixed message type.\n",
    "\n",
    "Now let's see if we can parse and return some actual image data.\n",
    "\n",
    "First, clear the logfile:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile logger.txt\n",
    "# Responder logfile\n",
    "# -----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see if we can collect an image data sample. Note that we are still using the `json_responder()` but with the `image_parser` (as set by `parser = image_parser`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sim_magic_preloaded -b Simple_Shapes --collab -ARO -x 520 -y 900\n",
    "import time\n",
    "\n",
    "print(\"PY::{'test_key':'test value'}\")\n",
    "\n",
    "# Give the messages time to pass\n",
    "time.sleep(1)\n",
    "print(\"IMG_DATA\")\n",
    "\n",
    "time.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should hopefully see an echo of a large amount of sensor data appear in the simulator output window. We should also be able to see it in the Python logfile:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cat logger.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "activity": true
   },
   "source": [
    "### 5.1.5 Activity â€” Reviewing the inter-agent message protocol and communication activity \n",
    "\n",
    "At this point, let's quickly recap the messaging protocol we have defined by way of another sequence diagram:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "activity": true
   },
   "outputs": [],
   "source": [
    "%%seqdiag\n",
    "default_fontsize = 24;\n",
    "edge_length = 220;\n",
    "activation = none;\n",
    "\n",
    "robot  -> responder [label = \"IMG_DATA::data\"];\n",
    "responder -> agent -> parser [label='message'];\n",
    "agent <- parser [label='object'];\n",
    "agent -> MLP [label='object'];\n",
    "agent <- MLP [label='classification'];\n",
    "responder <- agent [label='response'];\n",
    "responder --> logger [label = \"log message and response\"];\n",
    "robot <- responder [label = \"JSON::response\"];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "student": true
   },
   "source": [
    "*In your own words, describe the sequence of message-passing actions depicted by the sequence diagram here.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "activity": true,
    "heading_collapsed": true
   },
   "source": [
    "#### Example interpretation\n",
    "\n",
    "*Click on the arrow in the sidebar or run this cell to reveal an example interpretation.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "activity": true,
    "hidden": true
   },
   "source": [
    "In the sequence diagram, the *robot* passes a message (`IMG_DATA`) containing image data to the Python *agent*. The *agent* has the message parsed by the *parser*, converts the response to an image pair, and passes one of the images to the *MLP* neural network. The *MLP* classifies the image and returns a prediction to the *agent*. The *agent* creates a response and passes it to the *responder*, which encodes the response as a text message and sends it to the *robot*. The robot then parses the message as a JavaScript object and uses it as required."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Putting the pieces together â€” a multi-agent system\n",
    "\n",
    "With our message protocol defined, let's see if we can now create a multi-agent system where the robot collects some image data and passes it to the Python agent. The Python agent should then decode the image data, present it to a pre-trained multi-layer perceptron neural network, and identify a presented shape. The Python agent should then inform the robot about the shape of the object the robot can see."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.1 The image classifier agent\n",
    "\n",
    "To perform the recognition task, we need to implement our agent. The agent will take the image data and place it in a two row dataframe in the correct form. Then it will generate an image pair from the dataframe, and present the left-hand shape image to the neural network. The neural network will return a shape prediction and this will be passed in a message back to the robot.\n",
    "\n",
    "First, lets load in a pre-trained shape recognising MLP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import load\n",
    "\n",
    "MLP = load('mlp_shapes_14x14.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And let's set up the category labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the classes\n",
    "shapemap = {'square': 0,\n",
    "            'right facing triangle': 1,\n",
    "            'left facing triangle': 2,\n",
    "            'downwards facing triangle': 3,\n",
    "            'upwards facing triangle': 4,\n",
    "            'diamond': 5\n",
    "           }\n",
    "\n",
    "codemap = {shapemap[k]:k for k in shapemap}\n",
    "codemap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nn_tools.sensor_data import get_sensor_image_pair, image_data_to_array\n",
    "from nn_tools.sensor_data import zoom_img, image_data_to_array, image_from_array\n",
    "from nn_tools.network_views import class_predict_from_image\n",
    "\n",
    "def shape_recognising_agent(msg):\n",
    "    \"\"\"Shape recognising agent.\"\"\"\n",
    "    if msg['typ'] == 'IMG_DATA':\n",
    "        pair_index = -1\n",
    "        image_data = pd.DataFrame([{'side':'left', 'vals': roboSim.process_raw_image_data(msg['obj']['left'])},\n",
    "                                   {'side':'right', 'vals': roboSim.process_raw_image_data(msg['obj']['right'])}])\n",
    "        \n",
    "        left_img, right_img = get_sensor_image_pair(image_data,\n",
    "                                            pair_index)\n",
    "        prediction = class_predict_from_image(MLP, left_img)\n",
    "    # Suppose we have a dictionary response\n",
    "    # Just echo that back\n",
    "    return {'report': f'Agent says: I saw {codemap[prediction]}',\n",
    "            'shape': codemap[prediction]}\n",
    "\n",
    "agent = shape_recognising_agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see if we can help the robot recognise a shape:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sim_magic_preloaded -b Simple_Shapes --collab -ARO -x 520 -y 900\n",
    "import time\n",
    "\n",
    "print(\"IMG_DATA\")\n",
    "# Give the messages time to pass\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try another:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sim_magic --collab -ARO -x 200 -y 900"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try a slightly more elaborate handler on the robot side:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sim_magic_preloaded -b Simple_Shapes --collab -ARO -x 520 -y 900\n",
    "import time\n",
    "import ev3dev2_glue as glue\n",
    "\n",
    "print(\"IMG_DATA\")\n",
    "# Give the messages time to pass\n",
    "time.sleep(1)\n",
    "\n",
    "msg_queue = glue.pyState()\n",
    "print(msg_queue)\n",
    "# Get the last message\n",
    "possible_shape = msg_queue['messages'][-1]['message']['shape']\n",
    "say(\"Is that a \" + possible_shape )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "activity": true
   },
   "source": [
    "Run the following code cell several times to test the robot on different randomly sampled shapes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random_shape_x = 200 + random.randint(0, 5)*80\n",
    "\n",
    "%sim_magic --collab -ARO -x 200 -y 900"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "student": true
   },
   "source": [
    "*Record your observations here about how well the robot performed.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "student": true
   },
   "source": [
    "*Note down any other ideas you have about how a robot might be able to cooperate with other agents as part of a multi-agent system.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 Summary\n",
    "\n",
    "In this notebook, you have seen how we can create a simple protocol that allows the passage of messages between the robot and Python agent in a simple multi-agent system. The Python agent picks up the message received from the robot, parses it and decodes it as an image. The image is then classified by an MLP and the agent responds to the robot with a predicted image classification.\n",
    "\n",
    "You also saw how we can use a particular type of diagram, often referred to as a *sequence diagram*, to describe the passage of messages between several different actors in a communication system. Specialised diagram types play a significant role in many engineering disciplines for depicting in a structured way a visual description of a system or a visual summary of its anticipated operational behaviour. \n",
    "\n",
    "Whilst we only considered how our Python agent might call on a neural network to support our remote simulated robot agent, you might also conclude, correctly, that we could also use a \"traditional\" sequential program, or even a rule based system, to perform \"off-board\" tasks on behalf of the robot.\n",
    "\n",
    "This largely completes our journey into the world of introductory robot programming and neural networks. All that remains now is for you to read through the final notebook and recap the journey we have taken over the last few weeks."
   ]
  }
 ],
 "metadata": {
  "finalized": {
   "timestamp": 1603788970900,
   "trusted": true
  },
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "ipynb,.md//md"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
