{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "right-housing",
   "metadata": {},
   "source": [
    "# Introducing sensor-based navigation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "certified-poker",
   "metadata": {},
   "source": [
    "The main purpose of this session is to consider how robots can navigate in the world using their sensors.\n",
    "\n",
    "We will start by reviewing a sensor you have already met briefly: an *ultrasonic* sensor. Ultrasonic sensors can be used to detect obstacles, which can be useful if we want to prevent our robot from bumping into things or having its progress impeded by things that are in its way.\n",
    "\n",
    "Then you will learn how we can use motor tachometer sensors that allow the simulated robot to keep track of how far it has travelled (or at least, how many times its wheels have turned round) and a gyroscope to monitor the direction in which the robot is pointing.\n",
    "\n",
    "As usual, this session contains some activities and challenges. It finishes with some optional challenges to navigate a robot in worlds cluttered up with blocks.\n",
    "\n",
    "However, this week is relatively light in terms of practical activity content, so if you have time to spare you might find it useful to look at the practical activity part of the TMA."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seasonal-vintage",
   "metadata": {},
   "source": [
    "# 1 The RoboLab sensors\n",
    "\n",
    "In most of the activities we have completed to date, we have relied on the light sensor to provide sensory input to the robot control program.\n",
    "\n",
    "In this notebook, we will review some of the other sensors that are available to us, including an ultrasonic distance sensor, a direction-revealing gyroscope and tachometer ‘sensor’ readings that are reported by the motors. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "narrow-evolution",
   "metadata": {},
   "source": [
    "## 1.1 Available sensors\n",
    "\n",
    "Recall from previous activities that the simulated robot is configured with a variety of sensors, including two downward-facing light sensors, an ultrasonic sensor and a gyroscope (gyro).\n",
    "\n",
    "In this notebook, we will have a further look at how sensors are configured in the simulator.\n",
    "\n",
    "By default, on the simulated robot the light sensors are located at the front, just to the left and right of the centreline, although we could configure them to be in different locations. The light sensors are also assumed to be facing downwards so that they detect the colour/brightness of the background. You have already explored how we might model raising and lowering the light sensor in a previous notebook.\n",
    "\n",
    "The Lego Mindstorms EV3 ‘brick’, which inspired the original `ev3devsim` simulator from which the RoboLab `nbev3desim` simulator is derived, is a simple but otherwise typical robot control system: it has input and output *ports* to which different sensors and actuators can be connected:\n",
    "\n",
    "![](../images/nogbad_ev3.jpg)\n",
    "\n",
    "The EV3 brick itself contains a microprocessor running Linux and a rechargeable battery pack, four input ports labelled 1 to 4 for connecting sensors, four output ports labelled A to D for connecting motor outputs, a grey on/off button, four cursor control buttons (up, down, left, right) surrounding a central select button, and a small display screen.\n",
    "\n",
    "![](../images/ev3_sensors_motors.png)\n",
    "\n",
    "The control system needs to know what sensors and actuators are actually connected so that the input and output signals can be interpreted correctly.\n",
    "\n",
    "Motors are configured relative to specified input ports, conventionally output ports B and C:\n",
    "\n",
    "```python\n",
    "from ev3dev2.motor import OUTPUT_B, OUTPUT_C\n",
    "```\n",
    "\n",
    "The sensors are configured in a program by identifying the physical port they are connected to and the type of sensor they are:\n",
    "\n",
    "```python\n",
    "from ev3dev2.sensor import INPUT_1, INPUT_2, INPUT_3, INPUT_4\n",
    "from ev3dev2.sensor.lego import ColorSensor, GyroSensor, UltrasonicSensor\n",
    "\n",
    "ultrasonic = UltrasonicSensor(INPUT_1)\n",
    "colorLeft = ColorSensor(INPUT_2) <!-- JD: changed to colorLeft and INPUT_3 (which was a duplicate of the following line). -->\n",
    "colorRight = ColorSensor(INPUT_3)\n",
    "gyro = GyroSensor(INPUT_4)\n",
    "```\n",
    "\n",
    "To simplify configuration setting, the `%sim_magic_imports` and `%sim_magic_preloaded` magics load in port identifiers and motor and sensor objects respectively.\n",
    "\n",
    "Load in the simulator and magics in the normal way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moderate-olive",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbev3devsim.load_nbev3devwidget import roboSim, eds\n",
    "\n",
    "%load_ext nbev3devsim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rocky-place",
   "metadata": {},
   "source": [
    "and then preview the full range of supplied definitions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "remarkable-employment",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "%sim_magic_preloaded --preview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subject-sodium",
   "metadata": {
    "tags": [
     "alert-warning"
    ]
   },
   "source": [
    "*Remember, you can always check exactly what code has been downloaded to the simulator by viewing the `Code display` panel using the toggle display button in the simulator, the simulator `D` keyboard shortcut, or the `--code / -D` magic switch.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "delayed-mayor",
   "metadata": {},
   "source": [
    "### 1.1.2 Previewing sensor and motor objects\n",
    "\n",
    "To see what attributes and methods are associated with each of the defined objects, we can use the Python `dir()` function that displays the structure of a Python object.\n",
    "\n",
    "For example, we can view what’s on offer from the ultrasonic sensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "residential-wedding",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sim_magic_preloaded -OHWR\n",
    "\n",
    "# Show the contents of the ultrasonic object\n",
    "print(\"Ultrasonic sensor:\\n\")\n",
    "print(dir(ultrasonic))\n",
    "print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quality-tender",
   "metadata": {},
   "source": [
    "We see that available options include `.distance_centimeters` and `.distance_inches`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "otherwise-cover",
   "metadata": {},
   "source": [
    "Let’s have a look at the light sensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "monthly-establishment",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sim_magic_preloaded -OHWR\n",
    "\n",
    "# Show the contents of a light sensor object\n",
    "print(\"Light sensor:\\n\")\n",
    "print(dir(colorLeft))\n",
    "print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sacred-stevens",
   "metadata": {},
   "source": [
    "We see that available options include things like `color_name`, `full_reflected_light_intensity`, separate `red`, `green` and `blue` components as well as the combined `rgb` value and the `reflected_light_intensity` and  `reflected_light_intensity_pc` values we are familiar with."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "perfect-departure",
   "metadata": {},
   "source": [
    "Let’s look at one of the motor drives:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "natural-longer",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sim_magic_preloaded -OHWR\n",
    "\n",
    "# Show the contents of a motor drive object\n",
    "print(\"Tank drive:\\n\")\n",
    "print(dir(tank_drive))\n",
    "print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "increased-brunswick",
   "metadata": {},
   "source": [
    "Here we see `left_motor` and `right_motor` elements, among others. Let’s look at one of those:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "apart-sheep",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sim_magic_preloaded -OHWR\n",
    "\n",
    "# Show the contents of a motor object\n",
    "print(\"Tank turn -  motor:\\n\")\n",
    "print(dir(tank_turn.left_motor))\n",
    "print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "preliminary-wonder",
   "metadata": {},
   "source": [
    "Here we see a range of attributes and settings, but the one that will most interest us is the `.position` value, which is a record of the number of tacho counts recorded by the motor.\n",
    "\n",
    "Note that not all the components may be properly defined. (The package implementation is partial, although its API is relatively complete.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "checked-station",
   "metadata": {},
   "source": [
    "### 1.1.3 Charting sensor data\n",
    "\n",
    "To chart the sensor data using the live chart, we need to select the relevant trace in the simulator *Chart* panel and stream data in the correct form to it.\n",
    "\n",
    "Sensor data is sent to the chart using `print()` messages of the form:\n",
    "\n",
    "```python\n",
    "# Sensor display\n",
    " \n",
    "## left light sensor:\n",
    "print('Light_left: ' + str(colorLeft.reflected_light_intensity_pc))\n",
    "# We can also use other \n",
    "# reportable light sensor attributes\n",
    "\n",
    "# right light sensor\n",
    "print('Light_right: ' + str(colorLeft.reflected_light_intensity))\n",
    "# We can also use other \n",
    "# reportable light sensor attributes\n",
    "\n",
    "# right light sensor colour\n",
    "print('Colour: ' + str(colorLeft.color))\n",
    "\n",
    "\n",
    "# Ultrasonic\n",
    "print('Ultrasonic: ' + str(ultrasonic))\n",
    "\n",
    "# Motor tachometry - depending on drive\n",
    "print('Wheel_left: ' + str(tank_drive.left_motor.position))\n",
    "\n",
    "print('Wheel_right: ' + str(str(tank_turn.right_motor.position)))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "satisfactory-turkey",
   "metadata": {
    "activity": true
   },
   "source": [
    "### 1.1.4 Activity – Testing the ultrasonic sensor\n",
    "\n",
    "In this activity you will see how the ultrasonic sensor can be used in the simulator.\n",
    "\n",
    "The robot will drive forward, at speed, until it observes an obstacle, at which point it will start to slow down.\n",
    "\n",
    "Note that the ultrasonic sensor is mounted a little way back from the front edge of the robot, so we need to take that offset into account when deciding that the front of the robot is in contact with an obstacle."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "willing-savings",
   "metadata": {
    "activity": true
   },
   "source": [
    "The following code cell configures the simulator to use a blank background (`-b Empty_Map`) and a single obstacle (`Central_post`); the simulated robot is initially situated to near the mid-point of the left-hand edge of the simulator canvas (`-x 100 -y 500`) and ultrasonic rays are displayed (`-u`).\n",
    "\n",
    "Open the chart display in the simulator and ensure the *Ultrasonic* trace option is selected.\n",
    "\n",
    "Run the code cell to configure the simulator and download the program and then run the program in the simulator.\n",
    "\n",
    "Observe what happens and record your observations, paying attention to both the behaviour of the robot and the measurements returned by the ultrasonic sensor in the output window and/or the live chart.\n",
    "\n",
    "What happens if you initially locate the robot at `-x 100 -y 450`?\n",
    "\n",
    "When you have observed what happens, closely read through the program. How does the code explain the behaviour of the robot?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "educated-fence",
   "metadata": {
    "student": true
   },
   "source": [
    "*Use this cell to record your observations of what happens when the program is run.*\n",
    "\n",
    "*Annotate the program with comments to explain how it works.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "former-journal",
   "metadata": {
    "activity": true
   },
   "outputs": [],
   "source": [
    "%%sim_magic_preloaded -u -b Empty_Map -cC -o Central_post -x 100 -y 500\n",
    "\n",
    "import time\n",
    "ultrasonic = UltrasonicSensor(INPUT_1)\n",
    "\n",
    "u = ultrasonic.distance_centimeters\n",
    "print('Ultrasonic: ' + str(u))\n",
    "time.sleep(1)\n",
    "while  u > 3:\n",
    "    u = ultrasonic.distance_centimeters\n",
    "    print('Ultrasonic: ' + str(u))\n",
    "    u = min(100, u)\n",
    "    left_motor_speed = SpeedPercent(u)\n",
    "    right_motor_speed = SpeedPercent(u)\n",
    "    tank_drive.on(left_motor_speed, right_motor_speed)\n",
    "    \n",
    "say(\"All done...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liberal-tunnel",
   "metadata": {
    "activity": true,
    "heading_collapsed": true
   },
   "source": [
    "#### Example discussion\n",
    "\n",
    "*Click the arrow on the left or run this cell to reveal an example discussion.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "behavioral-brighton",
   "metadata": {
    "activity": true,
    "hidden": true
   },
   "source": [
    "When the program is run, the robot remains stationary for a moment or two before driving forward at some speed. As the simulated robot approaches the obstacle, it starts to slow down, coming to stop as it reaches the obstacle.\n",
    "\n",
    "Starting from the second location, the robot behaves in a similar way to the first run, but it doesn’t stop when it reaches the obstacle. Rather, it runs over the obstacle, slowly at first, then speeds up as it passes the obstacle.\n",
    "\n",
    "It seems that as the robot does not get very close to the obstacle *as measured by the ultrasonic sensor*, it does not stop. Instead, it continues moving and as the obstacle gets further away, the robot speeds up.\n",
    "\n",
    "Looking at the program, I have annotated it to describe what each line does and relate it to my observations of the robot’s behaviour:\n",
    "\n",
    "```python\n",
    "# Import a package \n",
    "import time\n",
    "\n",
    "# Create a variable associated with the ultrasonic sensor\n",
    "ultrasonic = UltrasonicSensor(INPUT_1)\n",
    "\n",
    "# Read the distance measured by the sensor\n",
    "u = ultrasonic.distance_centimeters\n",
    "\n",
    "# Display the distance\n",
    "print('Ultrasonic: ' + str(u))\n",
    "\n",
    "# Pause for 1 second - this is the delay before the robot starts moving\n",
    "time.sleep(1)\n",
    "# The delay is actually to give the ultrasonic sensor time to start working\n",
    "\n",
    "# If the distance is greater than three centimeters\n",
    "while  u > 3:\n",
    "    # Take the reading again\n",
    "    u = ultrasonic.distance_centimeters\n",
    "    \n",
    "    # Display the reading\n",
    "    # This also provides the data for the chart trace\n",
    "    print('Ultrasonic: ' + str(u))\n",
    "    \n",
    "    # Find the minimum value between the sensor reading and 100\n",
    "    u = min(100, u)\n",
    "    \n",
    "    # Set the motor speeds relative to the distance\n",
    "    # so the closer the robot is to the obstacle,\n",
    "    # the slower it will go.\n",
    "    left_motor_speed = SpeedPercent(u)\n",
    "    right_motor_speed = SpeedPercent(u)\n",
    "    \n",
    "    # Drive the robot at the desired speed\n",
    "    tank_drive.on(left_motor_speed, right_motor_speed)\n",
    "    \n",
    "# We're out of the whole loop, so the distance to the obstacle\n",
    "# must be less than or equal to three centimeters\n",
    "\n",
    "# And we're done... Print a message to announce the fact.\n",
    "print(\"All done...\")\n",
    "```\n",
    "\n",
    "The display of the distance measurement provided by the ultrasonic sensor shows an initial steep drop at the start of the chart as the sensor resets, and then a graceful decline as the robot moves towards the obstacle.\n",
    "\n",
    "Even though the robot encounters the obstacle, the robot drives over the obstacle rather than being stopped by it. The simulator physics are obviously not so complicated that obstacles have any simulated ‘physical’ substance to them capable of impeding the progress of the robot."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optimum-object",
   "metadata": {},
   "source": [
    "## 1.2 Summary\n",
    "\n",
    "In this notebook, we have reviewed the sensors that are available to use in the simulator, as well as how we might configure and refer to them using the boilerplate imports provided by the simulator magics.\n",
    "\n",
    "You then experimented with the ultrasonic sensor to see how it can be used to control the behaviour of the robot when it perceives an obstacle.\n",
    "\n",
    "<!-- JD: add something about the next notebook? -->"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,.md//md"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
