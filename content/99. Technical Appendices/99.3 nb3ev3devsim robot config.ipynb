{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "vocal-munich",
   "metadata": {},
   "source": [
    "# Appendix – Configuring the `nbev3devsim` simulated robot\n",
    "\n",
    "This notebook is a technical reference document that describes in a bit more detail how the simulated robot in the `nbev3devsim` simulator is configured.\n",
    "\n",
    "Note that this information is provided for informational purposes only. If the configuration of the robot away from the default values is required, any required changes and how to make them will be described in the associated activity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "divided-bulletin",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "from nbev3devsim.load_nbev3devwidget import roboSim, eds\n",
    "\n",
    "%load_ext nbev3devsim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sealed-cycle",
   "metadata": {},
   "source": [
    "## Robot configuration overview\n",
    "\n",
    "The `nbev3devsim` simulator allows robots to be configured using various components on specific input and output ports as defined in the `ev3dev` package developed for use with the EV3 Lego Mindstorms controller brick:\n",
    "\n",
    "- `OUTPUT_B`: left motor (state can be running or blank, not ramping, holding, overloaded, or stalled; stop action is ignored and the robot always stops instantly; `SpeedPercent`, `SpeedNativeUnits`, `SpeedRPS`, `SpeedRPM`, `SpeedDPS`, `SpeedDPM` are all defined, as are [`MotorSet`](https://ev3dev-lang.readthedocs.io/projects/python-ev3dev/en/stable/motors.html#motor-set), [`MoveTank`](https://ev3dev-lang.readthedocs.io/projects/python-ev3dev/en/stable/motors.html#move-tank) and [`MoveSteering`](https://ev3dev-lang.readthedocs.io/projects/python-ev3dev/en/stable/motors.html#move-steering) motor groups)\n",
    "- `OUTPUT C`: right motor.\n",
    "\n",
    "\n",
    "The simulated robot also supports a range of sensors:\n",
    "\n",
    "- an ultrasonic sensor (`UltrasonicSensor`) that is polled at the relatively slow rate of 10 times a second and that can be used to detect obstacles ahead of the sensor with an angle of incidence of no more than 50&nbsp;degrees (this models the behaviour of an actual ultrasonic whereby if the angle of incidence is too large, the ultrasound signal is reflected away from the sensor and no reading is recorded)\n",
    "- one or more downward-facing light/colour sensors (`ColorSensor`) that can be used to sense coloured readings on the world canvas directly below the sensor; sensors give readings between 0...255; in `nbev3devsim`, access is also provided to the light sensor pixel array, which effectively models a simple, low-resolution camera\n",
    "- a gyroscope sensor (`GyroSensor`) that measures the angle of the robot in accumulated degrees turned since the sensor was enabled.\n",
    " \n",
    "The sensors are available on predefined sensor input ports. The ultrasonic and colour sensors are mounted at default positions on the robot, although the position can be reconfigured using the robot configuration file:\n",
    "\n",
    "- `INPUT 1` : ultrasonic sensor; by default, this is mounted *front and centre* on the robot; [ultrasonic sensor](https://ev3dev-lang.readthedocs.io/projects/python-ev3dev/en/stable/sensors.html#ultrasonic-sensor) (readings provided for angles of incidence up to 50&nbsp;degrees; slow update rate of an actual ultrasonic sensor is simulated with reading updates approximately every 0.1&nbsp;s)\n",
    "- `INPUT 2` : colour sensor; by default, mounted *front and left* on the robot; left [colour sensor](https://ev3dev-lang.readthedocs.io/projects/python-ev3dev/en/stable/sensors.html#color-sensor) (raw values ranges between 0 and 255; ambient_light_intensity will always return 0; color and color_name may not give the same value as the actual sensor)\n",
    "- `INPUT 3` : colour sensor; by default, mounted *front and right* on the robot; `INPUT 3`: right colour sensor\n",
    "- `INPUT 4` : gyro sensor; fixed location in the centre of the robot; [gyro sensor](https://ev3dev-lang.readthedocs.io/projects/python-ev3dev/en/stable/sensors.html#gyro-sensor).\n",
    "\n",
    "In the T176 residential school, several activities are defined using different floorplans, such as a circular racing track marked out on a flat surface that the robots must navigate round as quickly as possible. Such activities are essentially ‘two dimensional’ so you should not feel that just because the simulator we are using is essentially a two-dimensional simulator you are not doing a realistic robot-programming activity.\n",
    "\n",
    "(In actual fact, the simulator is more like 2.5D simulator in that it supports an obstacle layer that sits above the plane of the background and within which walls and other smaller obstacles can be detected by a simulated ultrasonic sensor. Note that to keep the ‘world physics’ provided by the simulation as simple as possible, the obstacles do not, in fact, impede the progress of the simulated robot.)\n",
    "\n",
    "The simulated world can be loaded with a selection of predefined background layouts, or uploaded custom layouts, and can be used as the basis of specific robot programming tasks or challenges."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "systematic-diameter",
   "metadata": {
    "tags": [
     "alert-success"
    ]
   },
   "source": [
    "Layouts are sized 2362 by 1143 pixels, which corresponds to the size of a First Lego League / World Robot Olympiad (WRO) field mat, with 1&nbsp;pixel representing 1&nbsp;mm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "victorian-louis",
   "metadata": {},
   "source": [
    "The colour sensors can obtain readings from traces on the canvas layer that loads the floor mat; the ultrasonic sensor can sense obstacles on the mat although these are not physical objects that impede the progress of the robot. \n",
    "\n",
    "<img alt=\"Close up of simulated robot showing two wheel drive (one wheel on each side towards the front of the robot) and two light sensors at the front of the robot just to the left and right of the centreline.\" src=\"../images/EV3DEV_Python_Simulator_robot.png\" width=200 />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "drawn-constant",
   "metadata": {},
   "source": [
    "## Declaring motor and sensor configurations\n",
    "\n",
    "Motor and sensor settings are declared at the start of the downloaded program. To minimise the amount of repetitive boilerplate declaration code, two magics are defined that prepend downloaded code with boilerplate code.\n",
    "\n",
    "You can preview the code prepended to the downloaded programs by running them as a line magic with the `-v` or `--preview` flag:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bridal-undergraduate",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview prepended boilerplate code\n",
    "%sim_magic_imports --preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "likely-motivation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview prepended boilerplate code\n",
    "%sim_magic_preloaded -v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "becoming-transaction",
   "metadata": {},
   "source": [
    "## Magic configured robot manifestation settings\n",
    "\n",
    "As well as configuring sensor and motor setups programmatically via the downloaded code, the magics can be also be used to configure various properties of the ‘physical’ manifestation of the robot in the simulator.\n",
    "\n",
    "For example:\n",
    "\n",
    "- `--pendown` / `-p`: set the pen in pen-down mode (default is pen up); this can also be toggled using the keyboard shortcut `p` when the mouse cursor is over the simulator widget\n",
    "- `--xpos` / `-x` : set the x-coordinate\n",
    "- `--ypos` / `-y` : set the y-coordinate\n",
    "- `--angle` / `-a` : set the angle of rotation\n",
    "- `--sensornoise` / `-N` set the sensor noise level (0...128)\n",
    "- `--motornoise` / `-M` : set the motor noise level (0...500).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smooth-omega",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## Physical robot configuration\n",
    "\n",
    "The simulated robot itself is configured according to a simple set-up script that defines:\n",
    "\n",
    "- `wheeldiameter`: the diameter of the robot’s wheels (default: `56` mm)\n",
    "- `wheelSpacing`: the distance between the robot’s wheels; essentially, this defines the ‘width’ of the robot (default: `180` mm)\n",
    "- `back`: the distance to the back of the robot from the front; essentially, this defines the ‘height’ of the robot (default: `120` mm from the centreline between the wheels (TO DO – check))\n",
    "- `weight`: the weight of the robot (default: `medium`) (TO DO – does this affect physics at all?)\n",
    "- `sensor1`: the physical location on the robot of the colour sensor on `INPUT 2`, by default registered at location `(-20, 30)` from centre front of the robot and with diameter `20`\n",
    "- `sensor2`: the physical location on the robot of the colour sensor on `INPUT 3` at location `(20, 30)` and with diameter `20`\n",
    "- `ultrasonic`: the orientation and physical location on the robot of the ultrasonic sensor on `INPUT 1` (by default, in the front centre of the robot at (`0`, `20`) with angle `0` degrees relative to the front/back robot centreline).\n",
    "\n",
    "Various robot configurations can be updated via a drop-down list in the simulator *Settings* panel:\n",
    "\n",
    "![Screenshot showing robot config selection menu in nbev3devsim Settings panel](../images/nbev3devsim_robot_config_selector.png)\n",
    "\n",
    "Predefined robot configurations (named as shown in the drop-down list in the *Settings* panel) can also be selected via a magic switch:\n",
    "\n",
    "- `--robotSetup` / `-r`: robot config selection\n",
    "\n",
    "\n",
    "Clicking the *Robot config* toggle display button in the *Settings* panel displays an editable version of the actual robot physical configuration file in the *Robot configurator* panel.\n",
    "\n",
    "![Screenshot of the nbev3devsim robot configurator panel](../images/nbev3devsim_robot_config.png)\n",
    "\n",
    "\n",
    "After making any changes to the configuration, click the *Apply* button in the *Robot configurator* panel to commit them.\n",
    "\n",
    "The robot configuration object itself is a JSON (JavaScript Object Notation) object definition:\n",
    "\n",
    "```javascript\n",
    "{\n",
    "  \"wheeldiameter\": 56,\n",
    "  \"wheelSpacing\": 180,\n",
    "  \"back\": -120,\n",
    "  \"weight\": \"medium\",\n",
    "  \"sensor1\": {\n",
    "    \"x\": -20,\n",
    "    \"y\": 30,\n",
    "    \"diameter\": 20\n",
    "  },\n",
    "  \"sensor2\": {\n",
    "    \"x\": 20,\n",
    "    \"y\": 30,\n",
    "    \"diameter\": 20\n",
    "  },\n",
    "  \"ultrasonic\": {\n",
    "    \"x\": 0,\n",
    "    \"y\": 10,\n",
    "    \"angle\": 0\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "Robot configuration files can also be saved as `.json` files and imported/loaded into the simulator."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wooden-beaver",
   "metadata": {},
   "source": [
    "## Viewing programs downloaded to the simulated robot\n",
    "\n",
    "Run the following code cell to download a program to the simulator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "about-bathroom",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sim_magic\n",
    "\n",
    "# Move robot forward\n",
    "from ev3dev2.motor import MoveSteering, OUTPUT_B, OUTPUT_C\n",
    "\n",
    "motor_pair = MoveSteering(OUTPUT_B, OUTPUT_C)\n",
    "\n",
    "# Move robot forward for 3 seconds\n",
    "motor_pair.on_for_seconds(steering=0, speed=20, seconds=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "educated-injection",
   "metadata": {},
   "source": [
    "When the cell is run, you should get an audible alert to inform you that the code has been successfully downloaded.\n",
    "\n",
    "In the simulator, from the *Simulator controls* panel, click the *Code display* toggle button, use the `D` keyboard shortcut, or use the `-D` magic flag:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smooth-dinner",
   "metadata": {},
   "outputs": [],
   "source": [
    "%sim_magic -D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lucky-humor",
   "metadata": {},
   "source": [
    "## Viewing sensor and motor state\n",
    "\n",
    "Motor and sensor state values can be viewed via the simulator *Instrumentation* panel, which we can raise using the `--instrumentation` or `-i` magic flag:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thermal-jersey",
   "metadata": {},
   "outputs": [],
   "source": [
    "%sim_magic --instrumentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seventh-magic",
   "metadata": {},
   "source": [
    "The raw sensor array values can be displayed via the *Sensor arrays* panel, which we can raise using the `--array` or `-A` magic flag:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "solar-eugene",
   "metadata": {},
   "outputs": [],
   "source": [
    "%sim_magic --array"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,.md//md"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
