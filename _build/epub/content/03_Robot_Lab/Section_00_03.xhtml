<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml" xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <meta charset="utf-8" />
    <title>4 Emergent behaviour: Braitenberg’s vehicles</title>
    <link rel="stylesheet" href="../../_static/epub.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" /> 
  </head><body>

    <div class="document">
      <div class="documentwrapper">
          <div class="body" role="main">
            
  
<style>
/* CSS for nbsphinx extension */

/* remove conflicting styling from Sphinx themes */
div.nbinput.container,
div.nbinput.container div.prompt,
div.nbinput.container div.input_area,
div.nbinput.container div[class*=highlight],
div.nbinput.container div[class*=highlight] pre,
div.nboutput.container,
div.nboutput.container div.prompt,
div.nboutput.container div.output_area,
div.nboutput.container div[class*=highlight],
div.nboutput.container div[class*=highlight] pre {
    background: none;
    border: none;
    padding: 0 0;
    margin: 0;
    box-shadow: none;
}

/* avoid gaps between output lines */
div.nboutput.container div[class*=highlight] pre {
    line-height: normal;
}

/* input/output containers */
div.nbinput.container,
div.nboutput.container {
    display: -webkit-flex;
    display: flex;
    align-items: flex-start;
    margin: 0;
    width: 100%;
}
@media (max-width: 540px) {
    div.nbinput.container,
    div.nboutput.container {
        flex-direction: column;
    }
}

/* input container */
div.nbinput.container {
    padding-top: 5px;
}

/* last container */
div.nblast.container {
    padding-bottom: 5px;
}

/* input prompt */
div.nbinput.container div.prompt pre {
    color: #307FC1;
}

/* output prompt */
div.nboutput.container div.prompt pre {
    color: #BF5B3D;
}

/* all prompts */
div.nbinput.container div.prompt,
div.nboutput.container div.prompt {
    width: 4.5ex;
    padding-top: 5px;
    position: relative;
    user-select: none;
}

div.nbinput.container div.prompt > div,
div.nboutput.container div.prompt > div {
    position: absolute;
    right: 0;
    margin-right: 0.3ex;
}

@media (max-width: 540px) {
    div.nbinput.container div.prompt,
    div.nboutput.container div.prompt {
        width: unset;
        text-align: left;
        padding: 0.4em;
    }
    div.nboutput.container div.prompt.empty {
        padding: 0;
    }

    div.nbinput.container div.prompt > div,
    div.nboutput.container div.prompt > div {
        position: unset;
    }
}

/* disable scrollbars on prompts */
div.nbinput.container div.prompt pre,
div.nboutput.container div.prompt pre {
    overflow: hidden;
}

/* input/output area */
div.nbinput.container div.input_area,
div.nboutput.container div.output_area {
    -webkit-flex: 1;
    flex: 1;
    overflow: auto;
}
@media (max-width: 540px) {
    div.nbinput.container div.input_area,
    div.nboutput.container div.output_area {
        width: 100%;
    }
}

/* input area */
div.nbinput.container div.input_area {
    border: 1px solid #e0e0e0;
    border-radius: 2px;
    background: #f5f5f5;
}

/* override MathJax center alignment in output cells */
div.nboutput.container div[class*=MathJax] {
    text-align: left !important;
}

/* override sphinx.ext.imgmath center alignment in output cells */
div.nboutput.container div.math p {
    text-align: left;
}

/* standard error */
div.nboutput.container div.output_area.stderr {
    background: #fdd;
}

/* ANSI colors */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-default-inverse-fg { color: #FFFFFF; }
.ansi-default-inverse-bg { background-color: #000000; }

.ansi-bold { font-weight: bold; }
.ansi-underline { text-decoration: underline; }


div.nbinput.container div.input_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight].math,
div.nboutput.container div.output_area.rendered_html,
div.nboutput.container div.output_area > div.output_javascript,
div.nboutput.container div.output_area:not(.rendered_html) > img{
    padding: 5px;
}

/* fix copybtn overflow problem in chromium (needed for 'sphinx_copybutton') */
div.nbinput.container div.input_area > div[class^='highlight'],
div.nboutput.container div.output_area > div[class^='highlight']{
    overflow-y: hidden;
}

/* hide copybtn icon on prompts (needed for 'sphinx_copybutton') */
.prompt a.copybtn {
    display: none;
}

/* Some additional styling taken form the Jupyter notebook CSS */
div.rendered_html table {
  border: none;
  border-collapse: collapse;
  border-spacing: 0;
  color: black;
  font-size: 12px;
  table-layout: fixed;
}
div.rendered_html thead {
  border-bottom: 1px solid black;
  vertical-align: bottom;
}
div.rendered_html tr,
div.rendered_html th,
div.rendered_html td {
  text-align: right;
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}
div.rendered_html th {
  font-weight: bold;
}
div.rendered_html tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
div.rendered_html tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}
</style>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>#Testing  - can we load from a package?
#import _load_nbev3devwidget_requirements
##import _load_nbev3devwidget
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>#import _load_nbev3devwidget
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>#from IPython.display import Javascript
#Javascript(&#39;$( &quot;#notebook-container&quot; ).resizable({ghost: false})&#39;)
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span># If the above doesn&#39;t work, old skool is below...
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>from nbev3devsim import ev3devsim_nb as eds
import jp_proxy_widget

#Load the nbtutor extension
%load_ext nbtutor

#https://github.com/AaronWatters/jp_doodle/blob/master/notebooks/misc/JQueryUI%20dialogextend%20plugin%20demo.ipynb
#Load and initialise the jquery.dialogextend package

cdn_url = &quot;https://cdn.jsdelivr.net/npm/binary-com-jquery-dialogextended@1.0.0/jquery.dialogextend.js&quot;
cdn_url = eds.get_file_path(&#39;js/jquery.dialogextend.js&#39;)
module_id = &quot;dialogExtend&quot;

# Load the module using a widget (any widget -- the module loads to the global jQuery object).
loader = jp_proxy_widget.JSProxyWidget()

# Configure the module to be loaded.
loader.require_js(module_id, cdn_url)

# Load the module
loader.js_init(&quot;&quot;&quot;
    element.requirejs([module_identifier], function(module_value) {
        //element.html(&quot;loaded &quot; + module_identifier + &quot; : &quot; + module_value);
    });
&quot;&quot;&quot;, module_identifier=module_id)
loader

# I think we need to wait for this to load
# else we may get an error in next cell from dialogExtend not being available?
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>from nbev3devsim import ev3devsim_nb as eds

#Reset the notebook style
from IPython.core.display import display, HTML, Javascript

#display(HTML(&quot;&lt;style&gt;#notebook-container { resize:vertical; border: 5px solid;  width: 300px; resize: horizontal; overflow: auto; float:left !important;}&lt;/style&gt;&quot;))
display(HTML(&quot;&lt;style&gt;#notebook-container { width:50%; float:left !important;}&lt;/style&gt;&quot;))

#Launch the simulator
from nbev3devsim import ev3devsim_nb as eds
%reload_ext nbev3devsim

roboSim = eds.Ev3DevWidget()

roboSim.element.dialog();


roboSim.js_init(&quot;&quot;&quot;
element.dialog({ &quot;title&quot; : &quot;Robot Simulator&quot; }).dialogExtend({
        &quot;maximizable&quot; : true,
        &quot;dblclick&quot; : &quot;maximize&quot;,
        &quot;icons&quot; : { &quot;maximize&quot; : &quot;ui-icon-arrow-4-diag&quot; }});
&quot;&quot;&quot;)

display(roboSim)
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-javascript notranslate"><div class="highlight"><pre>
<span></span><span class="o">%%</span><span class="nx">javascript</span>
<span class="c1">//This allows us to resize this view</span>
<span class="c1">//Click on the right hand edge to drag</span>
<span class="nx">$</span><span class="p">(</span> <span class="s2">&quot;#notebook-container&quot;</span> <span class="p">).</span><span class="nx">resizable</span><span class="p">({</span><span class="nx">ghost</span><span class="o">:</span> <span class="kc">false</span><span class="p">})</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>%load_ext nbtutor
%load_ext nbev3devsim
</pre></div>
</div>
</div>
<div class="section" id="4-Emergent-behaviour:-Braitenberg’s-vehicles">
<h1>4 Emergent behaviour: Braitenberg’s vehicles</h1>
<p>In Study week 2 you came across Valentino Braitenberg’s ideas on the behaviour of robots <em>emerging</em> from the way they are wired up. The figure belows shows two ways of connecting sensors to motors. In (a), the left sensor is connected to the left motor and the right sensor is connected to the right motor. In (b) these connections are reversed.</p>
<p><img alt="Diagrams representing Braitenberg vehicles alongside simulated robots wired up in a similar fashion. A Braitenberg vehicle and our simulated robot are very similar: they have two wheels, one each side, and two light sensors, one on the left and one on the right of the front of the robot. A pair of Braitenberg vehicles are shown, one light avoiding and one seeking. A light avoiding vehicle has the left light sensor connected to the left motor and wheel, and the right light sensor connected to the right motor and wheel. A light seeking vehicle has the left light sensor connected to the right motor and wheel, and the right light sensor connected to the left wheel. The simulated robots have wiring indicating identical connections." src="../../_images/tm129_rob_p4_f008.gif" /></p>
<div class="section" id="4.1-Activity:-Testing-Braitenberg’s-vehicles">
<h2>4.1 Activity: Testing Braitenberg’s vehicles</h2>
<p>A ‘thought experiment’ suggests that the vehicle in figure (a) will move away from a light source. Similarly, another thought experiment suggests that the vehicle in figure (b) will move towards a light source. In the following activities you will test these predictions using an enivironment that models this set up, but uses downward facing light sensors that take measurements from a “light gradient” background, rather than forward facing light sensors that look for a light source at “eye-level”
(that is, sensor-level!).</p>
<div class="section" id="Reconfiguring-the-robot">
<h3>Reconfiguring the robot</h3>
<p>In order to detect different values from the light sensors on the right and left hand side of the robot, we need to reconfigure the robot so that the sensors are placed further apart than they are in the default robot configuration.</p>
<p>In the simulator, select the <em>Radial grey</em> background and check the <em>Pen down</em> checkbox.</p>
<p>You may notice that the simulator’s left and right light sensors appear to be further apart than they have been previously.</p>
<p>This has been done via a change to the robot configuration setting update that is applied automatically when the <em>Radial grey</em> background is loaded.</p>
<div class="section" id="Manually-Changing-the-Robot-Configuration-Settings">
<h4>Manually Changing the Robot Configuration Settings</h4>
<p>You can increase the spacing between the sensors by:</p>
<ul class="simple">
<li><p>clicking the <em>Configure Robot</em> button in the simulator to pop=up a window containing the robot configuration settings;</p></li>
<li><p>in the robot configuration settings window, scroll down to the <code class="docutils literal notranslate"><span class="pre">&quot;sensor1&quot;</span></code> parameters and change the <code class="docutils literal notranslate"><span class="pre">&quot;x&quot;</span></code> value from the default value of <code class="docutils literal notranslate"><span class="pre">-20</span></code> to the new value <code class="docutils literal notranslate"><span class="pre">-60</span></code>;</p></li>
<li><p>for <code class="docutils literal notranslate"><span class="pre">&quot;sensor2&quot;</span></code>, change the <code class="docutils literal notranslate"><span class="pre">&quot;x&quot;</span></code> value from its default value of <code class="docutils literal notranslate"><span class="pre">20</span></code> the new value <code class="docutils literal notranslate"><span class="pre">60</span></code>;</p></li>
<li><p>click the <em>Apply</em> button.</p></li>
</ul>
<p>If you look at the robot in the simulator, you should notice that the two light sensors are now located nearer the sides of the robot and are no longer located close to the centreline.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span># Linting is all a bit broken at the moment
# May or may not be ready in time...

#%load_ext pycodestyle_magic
#%pycodestyle_on
#%flake8_off --ignore D100
</pre></div>
</div>
</div>
</div>
<div class="section" id="Exploring-the-Radial-Grey-World">
<h4>Exploring the <em>Radial Grey</em> World</h4>
<p>Run the following code cell to download the programme to the simulator and then run it in the simulator. For now, don’t pay too much atttention to the code; our initial focus is purely on what we can observe about the behaviour of the robot.</p>
<p>Observe what happens paying particularly close attention to the trajectory the robot follows.</p>
<p>Enter a new starting location in the simulator, changing the original <em>Y</em> value from <code class="docutils literal notranslate"><span class="pre">400</span></code> to the new value <code class="docutils literal notranslate"><span class="pre">600</span></code>. Click the <em>Move</em> button to move the robot to that location and run the simulator again. How does the robot move this time?</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>%%sim_magic_preloaded

colorLeft = ColorSensor(INPUT_2)
colorRight = ColorSensor(INPUT_3)

while ((colorLeft.reflected_light_intensity&gt;0.05)
       and (colorRight.reflected_light_intensity)&gt;5):

    intensity_left = colorLeft.reflected_light_intensity
    intensity_right = colorRight.reflected_light_intensity

    print(intensity_left, intensity_right)

    left_motor_speed = SpeedPercent(intensity_left)
    right_motor_speed = SpeedPercent(intensity_right)

    tank_drive.on(left_motor_speed, right_motor_speed)
</pre></div>
</div>
</div>
<p>With the robot starting just <em>below</em> the centreline on the radial grey background, you shoul notice that as it moves across the background it veers away from the light on a path that curves towards the bottom right of the simulator, steering to the right from the robot’s perspective.</p>
<p>When the robot starts <em>above</em> the centreline, it veers away on the left hand side of the central bright point (that is, the robot steers to its left).</p>
<p>If the robot starts on the centreline, it continues on a straight path.</p>
<p>So how does the programme work?</p>
<p>If you inspect it closely, you will see it is split into several parts.</p>
<p>The first part just clarifies the sensor configuration:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">colorLeft</span> <span class="o">=</span> <span class="n">ColorSensor</span><span class="p">(</span><span class="n">INPUT_2</span><span class="p">)</span>
<span class="n">colorRight</span> <span class="o">=</span> <span class="n">ColorSensor</span><span class="p">(</span><span class="n">INPUT_3</span><span class="p">)</span>
</pre></div>
</div>
<p>Then we have a <code class="docutils literal notranslate"><span class="pre">while..</span></code> loop that ensures the programme keeps running unitl either the left or the right sensor value sees a particularly dark value:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">while</span> <span class="p">((</span><span class="n">colorLeft</span><span class="o">.</span><span class="n">reflected_light_intensity</span><span class="o">&gt;</span><span class="mi">5</span><span class="p">)</span>
       <span class="ow">and</span> <span class="p">(</span><span class="n">colorLeft</span><span class="o">.</span><span class="n">reflected_light_intensity</span><span class="p">)</span><span class="o">&gt;</span><span class="mi">5</span><span class="p">):</span>
</pre></div>
</div>
<p>Inside the <code class="docutils literal notranslate"><span class="pre">while..</span></code> block is the “intelligence” of the programme.</p>
<p>The values are displayed in the simulator output window using a <code class="docutils literal notranslate"><span class="pre">print()</span></code> statement, and are then used to set the motor speeds:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">left_motor_speed</span> <span class="o">=</span> <span class="n">SpeedPercent</span><span class="p">(</span><span class="n">intensity_left</span><span class="p">)</span>
<span class="n">right_motor_speed</span> <span class="o">=</span> <span class="n">SpeedPercent</span><span class="p">(</span><span class="n">intensity_right</span><span class="p">)</span>

<span class="n">tank_drive</span><span class="o">.</span><span class="n">on</span><span class="p">(</span><span class="n">left_motor_speed</span><span class="p">,</span> <span class="n">right_motor_speed</span><span class="p">)</span>
</pre></div>
</div>
<p>In this configuration:</p>
<ul class="simple">
<li><p>the percentage scaled <em>left</em> sensor value determines the speed value applied to the <em>left</em> motor, and</p></li>
<li><p>the percentage scaled <em>right</em> sensor value sets the <em>right</em> motor speed.</p></li>
</ul>
<p>The sensor value reports a higher reading the brighter the background. As the robot approaches the light source from below the centreline, the left sensor reads a higher value than the right sensor. As described by the programme, the left motor thus turns more quickly than the right motor, and so the robot turns toward its right hand side and veers away from the light source.</p>
<p>### Crossing the Wires…</p>
<p>Now let’s see what happens if we run the following program which uses:</p>
<ul class="simple">
<li><p>the <em>left</em> light sensor to control the speed of the <em>right</em> motor; and</p></li>
<li><p>the <em>right</em> light sensor to control the speed of the <em>left</em> motor.</p></li>
</ul>
<p>Still using the <em>Radial grey</em> background, clear the traces in the simulator.</p>
<p>Run the following code cell to download the programme to the simulator and then run it in the simulator.</p>
<p>Move the robot to the starting location <code class="docutils literal notranslate"><span class="pre">X=100,</span> <span class="pre">Y=700</span></code> and run the program again.</p>
<p>How does the robot’s behaviour with the “cross-wired” sensors and motors compare with the “direct”, same-side wiring?</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>%%sim_magic_preloaded

colorLeft = ColorSensor(INPUT_2)
colorRight = ColorSensor(INPUT_3)

while ((colorLeft.reflected_light_intensity&gt;5)
       and (colorRight.reflected_light_intensity)&gt;5):

    intensity_left = colorLeft.reflected_light_intensity
    intensity_right = colorRight.reflected_light_intensity

    print(intensity_left, intensity_right)

    left_motor_speed = SpeedPercent(intensity_right)
    right_motor_speed = SpeedPercent(intensity_left)

    tank_drive.on(left_motor_speed, right_motor_speed)
</pre></div>
</div>
</div>
<p>When the programme runs this time, the robot arcs <em>towards</em> the light: if it starts below the centre line, the robot turns to its left and up towards the light; if it starts above the light, the robot turns to its right, and curves down towards the light.</p>
</div>
<div class="section" id="Question">
<h4>Question</h4>
<p>How is the robot’s behaviour explained by the programme this time?</p>
<p><em>Double click this cell to edit it and enter your explanation of why the robot behaves as it does.</em></p>
</div>
<div class="section" id="Answer">
<h4>Answer</h4>
<p><em>Click the arrow in the sidebar to reveal my answer.</em></p>
<p>The sensor values are mapped onto motor speeds with the following lines of code:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">left_motor_speed</span> <span class="o">=</span> <span class="n">SpeedPercent</span><span class="p">(</span><span class="n">intensity_right</span><span class="p">)</span>
<span class="n">right_motor_speed</span> <span class="o">=</span> <span class="n">SpeedPercent</span><span class="p">(</span><span class="n">intensity_left</span><span class="p">)</span>

<span class="n">tank_drive</span><span class="o">.</span><span class="n">on</span><span class="p">(</span><span class="n">left_motor_speed</span><span class="p">,</span> <span class="n">right_motor_speed</span><span class="p">)</span>
</pre></div>
</div>
<p>In this configuration, the percentage scaled <em>right sensor</em> value determines the speed value applied to the <em>left motor</em>, and the percentage scaled left sensor* value sets the <em>right motor</em> speed.</p>
<p>As before, the sensor value reports a higher reading the brighter the background. As the robot approaches the light source from below the centreline, the left sensor reads a higher value than the right sensor. This results in the right motor turning more quickly than the left motor. As a result, the robot turns toward its left hand side and turns towards the light source.</p>
</div>
</div>
<div class="section" id="Looking-at-the-Data">
<h3>Looking at the Data</h3>
<p>To understand a little more closely what the sensors are seeing, click the <em>Show chart</em> checkbox in the simulator and select the <em>Left light</em> and <em>Right light</em> traces. The following programme streams the necessary data elements to the simulator output window.</p>
<p>Run the program and observe the behvavior of the traces.</p>
<p>How do the traces differ in value?</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>%%sim_magic_preloaded

colorLeft = ColorSensor(INPUT_2)
colorRight = ColorSensor(INPUT_3)

while ((colorLeft.reflected_light_intensity&gt;5)
       and (colorLeft.reflected_light_intensity)&gt;5):

    intensity_left = colorLeft.reflected_light_intensity
    intensity_right = colorRight.reflected_light_intensity

    left_motor_speed = SpeedPercent(intensity_right)
    right_motor_speed = SpeedPercent(intensity_left)

    tank_drive.on(left_motor_speed, right_motor_speed)
    print(&#39;Light_left: &#39; + str(intensity_left ))
    print(&#39;Light_right: &#39; + str(intensity_right))
</pre></div>
</div>
</div>
<p>By inspection of the traces, you should notice that one of them is always slightly higher than the other.</p>
<p>We can also inspect the data in the notebook directly by looking at the data returned in the notebook synchroised datalog.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>#Grab the logged data into a pandas dataframe
df = eds.get_dataframe_from_datalog(roboSim.results_log)

#Preview the first few rows of the dataset
df.head()
</pre></div>
</div>
</div>
<p>Plot the data from the dataframe using the <code class="docutils literal notranslate"><span class="pre">seaborn</span></code> scientific charting package:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>import seaborn as sns

# A line plot is a sensible chart type to use
# to plot the time series data
ax = sns.lineplot(x=&quot;index&quot;,
                  y=&quot;value&quot;,
                  hue=&#39;variable&#39;,
                  data=df)
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="Using-Ultrasound">
<h1>Using Ultrasound</h1>
<p>We can also create a Braitenberg vehicle that uses a single distance sensor to moderate its behaviour, for example to try to avoid obstacles.</p>
<p>Load in the <em>Obstacles Test</em> background, run the following code cell to download the programme to the simulator, and then run it in the simulator.</p>
<p>Record your observations of the the behaviour of the robot when the programme is run in the simulator with the robot starting in different positions. Based on your observations, what do sort of behaviour does the robot appear to be performing?</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-none notranslate"><div class="highlight"><pre>
<span></span>%%sim_magic_preloaded
import time
ultrasonic = UltrasonicSensor(INPUT_1)

u = ultrasonic.distance_centimeters
print(&#39;Ultrasonic: &#39; + str(u))
time.sleep(1)
while  u &gt; 1:
    u = ultrasonic.distance_centimeters
    print(&#39;Ultrasonic: &#39; + str(u))
    u = min(100, u)
    left_motor_speed = SpeedPercent(u)
    right_motor_speed = SpeedPercent(u)
    tank_drive.on(left_motor_speed, right_motor_speed)

</pre></div>
</div>
</div>
<p><em>Record your observations here about what the robot appears to be doing when the program is run in the simulator with the rovot starting in different positions.</em></p>
<p><em>Based solely on your observations, what sort of behaviour does the robot appear to be performing?</em></p>
<p><em>With reference to the programme, what actions is the robot actually performing?</em></p>
<p><em>Click the arrow in the sidebar to reveal my answer.</em></p>
<p><strong>TO DO</strong></p>
<div class="section" id="Summary">
<h2>Summary</h2>
<p>In this notebook you have experimented with some simple Braitenberg vehicles, seeing how a reactive control strategy based on some simple sensor inputs can lead to different emergent behabviours in the robot. In some cases, we might be tempted to call such behaviours “intelligent”, or to ascribe certain <em>desires</em> to the robot (such as ’<em>it</em><strong>wants</strong><em>to this</em>) but that is not really the case: the robot is simply reacting to particular inputs in a particular way.</p>
</div>
</div>


          </div>
      </div>
      <div class="clearer"></div>
    </div>
  </body>
</html>