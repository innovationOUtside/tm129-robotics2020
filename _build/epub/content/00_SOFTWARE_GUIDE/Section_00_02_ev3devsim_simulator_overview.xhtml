<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml" xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>The ev3devsim Simulator</title>
    <link rel="stylesheet" href="../../_static/epub.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" /> 
  </head><body>

    <div class="document">
      <div class="documentwrapper">
          <div class="body" role="main">
            
  <div class="section" id="The-ev3devsim-Simulator">
<h1>The <code class="docutils literal notranslate"><span class="pre">ev3devsim</span></code> Simulator</h1>
<p>An extension of the <code class="docutils literal notranslate"><span class="pre">ev3devsim</span></code> robot simulator will be the focus of many of the programming activities in this block. <code class="docutils literal notranslate"><span class="pre">ev3devsim</span></code> itself was inspired by (<code class="docutils literal notranslate"><span class="pre">ev3dev</span></code>)[<code class="docutils literal notranslate"><span class="pre">https://www.ev3dev.org/</span></code>], <em>“a Debian Linux-based operating system that runs on several LEGO® MINDSTORMS compatible platforms including the LEGO® MINDSTORMS EV3 and Raspberry Pi-powered BrickPi.”</em></p>
<p>Lego EV3 educational robots are widely used in all levels of education. For example, they are used in the Open University residential school course <em>T176 Engineering: professions, practice and skills 1</em>.</p>
<p>Low level functions provided by the <code class="docutils literal notranslate"><span class="pre">ev3dev</span></code> operating system are “wrapped” by the <a class="reference external" href="https://github.com/ev3dev/ev3dev-lang-python">ev3dev-lang-python</a><span class="link-target"> [https://github.com/ev3dev/ev3dev-lang-python]</span> Python 3 package. This means that a LEGO EV3 robot running the <code class="docutils literal notranslate"><span class="pre">ev3dev</span></code> operating system can be programmed using Python code.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">ev3devsim</span></code> package implements a cut down version of the [<code class="docutils literal notranslate"><span class="pre">ev3dev-lang-python</span></code>] library to control a browser based, 2D-simulated robot. The <code class="docutils literal notranslate"><span class="pre">ev3devsim</span></code> Python codes runs in a Skulpt interpreter (a browser based Python interpreter) to control a Javascript powered robot simulator.</p>
<p>The original <code class="docutils literal notranslate"><span class="pre">`ev3devsim</span></code> &lt;<a class="reference external" href="https://github.com/QuirkyCort/ev3dev-sim">https://github.com/QuirkyCort/ev3dev-sim</a>&gt;`__ simulator ran as a standalone web application that could be run, even in an offline mode, using just a web browser (<a class="reference external" href="https://www.aposteriori.com.sg/Ev3devSim/index.html">try it here</a><span class="link-target"> [https://www.aposteriori.com.sg/Ev3devSim/index.html]</span>).</p>
<p>[<img alt="Screenshot of original ev3devsim simulator showing robot simualtor canvas with simulated robot on a line following test track, the program editor containing a sample program, simulator program run controls (Run and Stop buttons) and a sensor data output window with example sensor output readings." src="../../_images/EV3DEV_Python_Simulator.png" /></p>
<p>Program code is entered into the editor window and run by clicking the simulator <em>Run</em> button and halts if there is an error or when the <em>Stop</em> button is pressed. An output window display messages sent from the program, such as sensor log values, as well as error messages if the programme throws an error when it is run.</p>
<p>Program files can be saved from, and loaded into the the program editor.</p>
<p>A range of predefined worlds can be loaded into the simulator, as image files, from a drop down menu.</p>
<p>Obstacles can be added to a world using a configuration file opened by clicking the <code class="docutils literal notranslate"><span class="pre">Obstacles</span></code> button.</p>
<p>The robot can be configured via a configuration menu.</p>
<p>The robot can be moved to a specifed location y speficifying target location oc-ordinates and clicking <code class="docutils literal notranslate"><span class="pre">Move</span></code>.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">`nbev3devsim</span></code> &lt;<a class="reference external" href="https://github.com/innovationOUtside/nbev3devsim">https://github.com/innovationOUtside/nbev3devsim</a>&gt;`__ package builds on the original <code class="docutils literal notranslate"><span class="pre">ev3devsim</span></code> to provide an <code class="docutils literal notranslate"><span class="pre">ipywidget</span></code> that embeds the simulator in a Jupyter notebook and allows it to be programmed from notebook code cells. Sensor data logged within the simulator can be exported to the notebook’s own Python environment and analysed using the full power of Python’s wide range of charting and data analysis packages.</p>
<p>Whilst the original <code class="docutils literal notranslate"><span class="pre">ev3devsim</span></code> simulator runs without any software requirements other than a modern web browser, the <code class="docutils literal notranslate"><span class="pre">nbev3devsim</span></code> approach does require the availability of a Jupyter notebook environment. Although this increases the complexity of the software environment, it does provide several benefits:</p>
<ol class="arabic simple">
<li><p>instructional material can be provided within a notebook to support each programming activity;</p></li>
<li><p>data retrieved from the simulator can be analysed and charted in the notebook kernel context (for example, using Python or R);</p></li>
<li><p>the notebook environment provides a read / write environment within which a learner can make their own notes and annotations, as well as keep a record of the various steps they took to develop any particular robot control programme.</p></li>
</ol>
</div>
<div class="section" id="The-EV3-“Brick”">
<h1>The EV3 “Brick”</h1>
<p>The physical EV3 controller is capable of supporting four motor outputs referred to as <code class="docutils literal notranslate"><span class="pre">OUTPUT</span> <span class="pre">A</span></code>, <code class="docutils literal notranslate"><span class="pre">OUTPUT</span> <span class="pre">B</span></code>, <code class="docutils literal notranslate"><span class="pre">OUTPUT</span> <span class="pre">C</span></code> and <code class="docutils literal notranslate"><span class="pre">OUTPUT</span> <span class="pre">D</span></code>. In the simulator, we define a simple two wheeled differential drive robout using two motors configured as follows:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">OUTPUT</span> <span class="pre">B</span></code>: left motor;</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">OUTPUT</span> <span class="pre">C</span></code>: right motor.</p></li>
</ul>
<p>THe EV3 brick also support four input ports to which four different, independent sensors can be attached. These range from touch sensors, to light sensors, infrared sensors, ultrasonic sensors and even gyroscopes.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">ev3devsim</span></code> simulator this simulates simple robots such as ones that can be built with LEGO Mindstorms.</p>
<p><strong>TO DO: this all needs updating, eg with image assets from T176 presentation.</strong></p>
<p>In fact, RobotLab was originally designed to work with LEGO Mindstorms RCX robots. Robots as simple as this are very useful for getting hands-on experience with robotics, but naturally they have some limitations compared with more sophisticated (and complex) robot systems. Some of the features of RobotLab and Simon will make more sense if you know a little bit about a simple robot system such as the LEGO Mindstorms RCX kit.</p>
<div xmlns:str="http://exslt.org/strings" style="background:lightblue"><p><p>Note: LEGO’s more recent Mindstorms NXT kits differ from the RCX version described here</p>
</p></div><p>The robot in Figure 2.2 is built around the LEGO Mindstorms RCX ‘brick’ which is shown in more detail in Figure 2.3. Inside the RCX brick there is a microprocessor and other circuitry. Think of it as a small computer. Built into the brick are three ‘sensor input ports’ labelled 1, 2 and 3, and three ‘actuator output ports’ labelled A, B and C, which are capable of powering motors.</p>
<p><img alt="figure ../tm129-19J-images/tm129_rob_p1_f021.jpg" src="content/00_SOFTWARE_GUIDE/../tm129-19J-images/tm129_rob_p1_f021.jpg" /></p>
<p>Figure 2.3 The RCX controller ‘brick’</p>
<p>The RCX controller ‘brick’, seen from above. This is a large piece of yellow Lego, about 8 x 14 studs in size. At the centre is a control panel with a small LCD screen surrounded by four buttons: these are labelled On-Off, Run, Prgm (Program) and View. Above the control panel are three sensor input ports, labelled 1, 2, 3. These take the form of 2 × 2 studs which are partly metallic. Below the control panel are three actuator output ports, labelled A, B, C. These also are 2 × 2 studs which are
partly metallic.</p>
<p>The <em>ports</em> are interfaces to the external world. Sensors can be attached to the input ports, allowing information about the environment to enter the computer. Motors and other actuators can be attached to the output ports, and the brick can switch them on and off and control their direction and power.</p>
<p>RobotLab assumes that the simulated robot works like an RCX brick. This means that RobotLab needs to know what kinds of sensors and actuators are being used, and how the (simulated) RCX is ‘configured’. You will see how this is done later.</p>
<p>Although I have described the simulated robot in terms of a simple Lego robot, similar considerations would apply to other robotics systems. The control subsystem of any robot is usually flexible and designed to be configured with a variety of sensors and actuators.</p>
<p><img alt="figure ../tm129-19J-images/tm129_rob_p1_f005.jpg" src="../../_images/nogbad_ev3.jpg" /></p>
<p>[Credit: Nigel Gibson / &#64;nogbad]</p>
</div>
<div class="section" id="Simulator-Overview">
<h1>Simulator Overview</h1>
<p>The <code class="docutils literal notranslate"><span class="pre">ev3devsim</span></code> simulator allows robots to be configured using various components on specific input and output ports:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">OUTPUT_B</span></code>: left motor (state can be running or blank, not ramping, holding, overloaded, or stalled; stop action is ignored and the robot always stops instantly; <code class="docutils literal notranslate"><span class="pre">SpeedPercent</span></code>, <code class="docutils literal notranslate"><span class="pre">SpeedNativeUnits</span></code>, <code class="docutils literal notranslate"><span class="pre">SpeedRPS</span></code>, <code class="docutils literal notranslate"><span class="pre">SpeedRPM</span></code>, <code class="docutils literal notranslate"><span class="pre">SpeedDPS</span></code>, <code class="docutils literal notranslate"><span class="pre">SpeedDPM</span></code> are all defined, as are <code class="docutils literal notranslate"><span class="pre">`MotorSet</span></code> &lt;<a class="reference external" href="https://ev3dev-lang.readthedocs.io/projects/python-ev3dev/en/stable/motors.html#motor-set">https://ev3dev-lang.readthedocs.io/projects/python-ev3dev/en/stable/motors.html#motor-set</a>&gt;`__,
<code class="docutils literal notranslate"><span class="pre">`MoveTank</span></code> &lt;<a class="reference external" href="https://ev3dev-lang.readthedocs.io/projects/python-ev3dev/en/stable/motors.html#move-tank">https://ev3dev-lang.readthedocs.io/projects/python-ev3dev/en/stable/motors.html#move-tank</a>&gt;`__ and <code class="docutils literal notranslate"><span class="pre">`MoveSteering</span></code> &lt;<a class="reference external" href="https://ev3dev-lang.readthedocs.io/projects/python-ev3dev/en/stable/motors.html#move-steering">https://ev3dev-lang.readthedocs.io/projects/python-ev3dev/en/stable/motors.html#move-steering</a>&gt;`__ motor groups);</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">OUTPUT</span> <span class="pre">C</span></code>: right motor;</p></li>
</ul>
<p>The simulated robot also supports a range of sensors:</p>
<ul class="simple">
<li><p>an ultrasonic sensor (<code class="docutils literal notranslate"><span class="pre">UltrasonicSensor</span></code>) that can be used to detect obstacles ahead [TO DO - CHECK] of the sensor. “In an actual ultrasonic sensor, if the angle of incident is too steep, the sound gets reflected away from the sensor resulting in no reading. We try to replicate this by providing readings only if the angle of incident is no more than 50 degrees. The slow update rate of an actual ultrasonic sensor is simulated; readings are only updated around 10 times per sec.” &lt;- from the
docs</p></li>
<li><p>one or more downward facing light / colour sensors (<code class="docutils literal notranslate"><span class="pre">ColorSensor</span></code>) that can be used to sense coloured readings on the world canvas directly below the sensor; sensors give readings of between 0..255.</p></li>
<li><p>a gyroscope sensor (<code class="docutils literal notranslate"><span class="pre">GyroSensor</span></code>) that measures the angle of the robot; the angle is measure in ??. A gyro reading of 0 corresponds to ??</p></li>
</ul>
<p>The sensors are available on predefined sensor inut ports. The ultrasonic and color sensors are mounted at default positions on the robot, although the position can be reconfigured using the robot configuration file:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">INPUT</span> <span class="pre">1</span></code> : ultrasonic sensor; by default, this is mounted <em>front and center</em> on the robot; <a class="reference external" href="https://ev3dev-lang.readthedocs.io/projects/python-ev3dev/en/stable/sensors.html#ultrasonic-sensor">ultrasonic sensor</a><span class="link-target"> [https://ev3dev-lang.readthedocs.io/projects/python-ev3dev/en/stable/sensors.html#ultrasonic-sensor]</span> (readings provided for angles of incidence up to 50 degrees; slow update rate of an actual ultrasonic sensor is simulated with reading updates approximately every 0.1s);</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">INPUT</span> <span class="pre">2</span></code> : color sensor by default, mounted <em>front and left</em> on the robot; left <a class="reference external" href="https://ev3dev-lang.readthedocs.io/projects/python-ev3dev/en/stable/sensors.html#color-sensor">color sensor</a><span class="link-target"> [https://ev3dev-lang.readthedocs.io/projects/python-ev3dev/en/stable/sensors.html#color-sensor]</span> (raw values ranges between 0 to 255; ambient_light_intensity will always return 0; color and color_name may not give the same value as the actual sensor);</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">INPUT</span> <span class="pre">3</span></code> : color sensor; by default, mounted <em>front and right</em> on the robot; <code class="docutils literal notranslate"><span class="pre">INPUT</span> <span class="pre">3</span></code>: right color sensor;</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">INPUT</span> <span class="pre">4</span></code> : gyro sensor; fixed location in the center of the robot; <a class="reference external" href="https://ev3dev-lang.readthedocs.io/projects/python-ev3dev/en/stable/sensors.html#gyro-sensor">gyro sensor</a><span class="link-target"> [https://ev3dev-lang.readthedocs.io/projects/python-ev3dev/en/stable/sensors.html#gyro-sensor]</span>.</p></li>
</ul>
<p>In the T176 residential school, several activities are defined using different floorplans, such a circular racing track marked out a flat surface that the robots must navigate round as quickly as possible. Such activities are essentially “two dimensional” so you should not feel that just because the simulator we are using is essentially a two dimensional simulator you are not doing a realistic robot programming activity.</p>
<p>(In actual fact, the simulator is more like 2.5D simulator in that it supports an obstacle layer that sits above the plane of the background and within which walls and other smaller obstacles can be detected by a simulated ultrasonic sensor. Note that to keep the “world physics” provided by the simulation as simple as possible, the obstacles do not, in fact, impede the progress of the simulated robot.</p>
<p><strong>TO DO - optionally impede progrgess if robot encouters wall or obstacle.</strong></p>
<p>The simulated world can be loaded with a selection of predefined background layouts, or uploaded custom layouts, can be used as the basis of specific robot programming tasks or challenges. (Layouts are sized 2362 by 1143 pixels, which corresponds to the size of a First Lego League / World Robot Olympiad (WRO) field mat, with 1 pixel representing 1mm.)</p>
<p>The colour sensors can obtain readings from traces on canvas layer that loads the floor mat; the ultrasonic sensor can sense obstacles on the mat although these are not physical objects that impede the progress of the robot.</p>
<p><img alt="Close up of simulated robot showing two wheel drive (one wheel on each side towards the front of the robot) and two light sensors at the front of the robot just to the left and right of the center line." src="../../_images/EV3DEV_Python_Simulator_robot.png" style="width: 200px;" /></p>
</div>
<div class="section" id="Robot-Configuration">
<h1>Robot Configuration</h1>
<p>The simulated robot itself is configured according to a simple set-up script that defines:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">wheeldiameter</span></code>: the diameter of the robot’s wheels (default: <code class="docutils literal notranslate"><span class="pre">56</span></code> mm);</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">wheelSpacing</span></code>: the distance between the robot’s wheels; essentially, this defines the “width” of the robot (default: <code class="docutils literal notranslate"><span class="pre">180</span></code> mm);</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">back</span></code>: the distance to the back of the robot from the front; essentially, this defines the “height” of the robot (default: <code class="docutils literal notranslate"><span class="pre">120</span></code> mm from the centreline between the wheels (TO DO - check));</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">weight</span></code>: the weight of the robot (default: <code class="docutils literal notranslate"><span class="pre">medium</span></code>) TO DO - does this affect physics at all?</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sensor1</span></code>: the physical location on the robot of the color sensor on <code class="docutils literal notranslate"><span class="pre">INPUT</span> <span class="pre">2</span></code> (<code class="docutils literal notranslate"><span class="pre">sensor1</span></code>, by default registered at location <code class="docutils literal notranslate"><span class="pre">(-20,</span> <span class="pre">30)</span></code> from centre front of the robot and with diameter <code class="docutils literal notranslate"><span class="pre">20</span></code>;</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sensor2</span></code>: the physical location on the robot of the color sensor on <code class="docutils literal notranslate"><span class="pre">INPUT</span> <span class="pre">3</span></code> at location <code class="docutils literal notranslate"><span class="pre">(20,</span> <span class="pre">30)</span></code> and with diameter <code class="docutils literal notranslate"><span class="pre">20</span></code>;</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">ultrasonic</span></code>: the orientation and physical location on the robot of the ultrasonic sensor on <code class="docutils literal notranslate"><span class="pre">INPUT</span> <span class="pre">1</span></code> (by default, in the front center of the robot at (<code class="docutils literal notranslate"><span class="pre">0</span></code>, <code class="docutils literal notranslate"><span class="pre">20</span></code>) with angle <code class="docutils literal notranslate"><span class="pre">0</span></code> degrees relative to the front/back robot center-line).</p></li>
</ul>
<p>The configuration can be updated via a pop-up window in the simulator.</p>
<p><img alt="Example of ev3devsim robot configuration window. SUBJECT TO CHANGE" src="../../_images/00_01_EV3DEV_Python_Simulator-config_robot.png" /></p>
<p>The robot configuration file is a JSON (Javascript Object Notation) object definition:</p>
<div class="highlight-javascript notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
  <span class="s2">&quot;wheeldiameter&quot;</span><span class="o">:</span> <span class="mi">56</span><span class="p">,</span>
  <span class="s2">&quot;wheelSpacing&quot;</span><span class="o">:</span> <span class="mi">180</span><span class="p">,</span>
  <span class="s2">&quot;back&quot;</span><span class="o">:</span> <span class="o">-</span><span class="mi">120</span><span class="p">,</span>
  <span class="s2">&quot;weight&quot;</span><span class="o">:</span> <span class="s2">&quot;medium&quot;</span><span class="p">,</span>
  <span class="s2">&quot;sensor1&quot;</span><span class="o">:</span> <span class="p">{</span>
    <span class="s2">&quot;x&quot;</span><span class="o">:</span> <span class="o">-</span><span class="mi">20</span><span class="p">,</span>
    <span class="s2">&quot;y&quot;</span><span class="o">:</span> <span class="mi">30</span><span class="p">,</span>
    <span class="s2">&quot;diameter&quot;</span><span class="o">:</span> <span class="mi">20</span>
  <span class="p">},</span>
  <span class="s2">&quot;sensor2&quot;</span><span class="o">:</span> <span class="p">{</span>
    <span class="s2">&quot;x&quot;</span><span class="o">:</span> <span class="mi">20</span><span class="p">,</span>
    <span class="s2">&quot;y&quot;</span><span class="o">:</span> <span class="mi">30</span><span class="p">,</span>
    <span class="s2">&quot;diameter&quot;</span><span class="o">:</span> <span class="mi">20</span>
  <span class="p">},</span>
  <span class="s2">&quot;ultrasonic&quot;</span><span class="o">:</span> <span class="p">{</span>
    <span class="s2">&quot;x&quot;</span><span class="o">:</span> <span class="mi">0</span><span class="p">,</span>
    <span class="s2">&quot;y&quot;</span><span class="o">:</span> <span class="mi">10</span><span class="p">,</span>
    <span class="s2">&quot;angle&quot;</span><span class="o">:</span> <span class="mi">0</span>
  <span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
<div class="alert-warning"><p>In <code class="docutils literal notranslate"><span class="pre">nbev3devsim</span></code>, there is the possibility of moving the set up either to a notebook code cell, a to simple <code class="docutils literal notranslate"><span class="pre">ipywidget</span></code> configurator, or via simulator magic parameters. This is currently on the long-list of to do items. The current pop up works fine.</p>
</div><!-- #endregion --></div>


            <div class="clearer"></div>
          </div>
      </div>
      <div class="clearer"></div>
    </div>
  </body>
</html>